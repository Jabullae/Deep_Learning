get_ipython().getoutput("pip install hyperopt")
get_ipython().getoutput("pip install imblearn")
get_ipython().getoutput("pip install missingno")
import missingno as msno
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns

import warnings
from IPython.display import Image

get_ipython().run_line_magic("config", " Completer.use_jedi = False")
get_ipython().run_line_magic("matplotlib", " inline")
get_ipython().run_line_magic("config", " InlineBackend.figure_format = 'retina'")

mpl.rc('font', family = 'D2coding')
mpl.rc('axes', unicode_minus = False)

sns.set(font = 'D2coding', rc = {'axes.unicode_minus':False}, style = 'darkgrid')
plt.rc('figure', figsize = (10, 8))

warnings.filterwarnings('ignore')


from sklearn.model_selection import train_test_split, cross_val_predict
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve, classification_report

from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import Binarizer


# 평가지표 분류
def get_clf_eval(y_test, pred = None, pred_proba = None):
    confusion = confusion_matrix(y_test, pred)
    accuracy = accuracy_score(y_test, pred)
    precision = precision_score(y_test, pred)
    recall = recall_score(y_test, pred)
    f1 = f1_score(y_test, pred)
    roc_auc = roc_auc_score(y_test, pred_proba)
    print('오차 행렬')
    print(confusion)
    print('정확도 : {:.4f}, 정밀도 : {:.4f}, 재현율 : {:.4f}, F1 : {:.4f}, AUC : {:.4f}'.
          format(accuracy, precision, recall, f1, roc_auc))

# 재현율과 정밀도의 시각화
def precision_recall_curve_plot(y_test, pred_proba_c1):
    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)
    
    plt.figure(figsize = (10, 7))
    plt.rc('font', family = 'D2coding')
    threshold_boundary = thresholds.shape[0]
    a = thresholds[precisions[0:threshold_boundary] == recalls[0:threshold_boundary]]
    loc = np.where(thresholds == a[0])[0][0]
    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle = '--', label = 'precision')
    plt.plot(thresholds, recalls[0:threshold_boundary], label = 'recall')
    plt.scatter(thresholds[loc], precisions[loc], c = 'black', s = 60)
    plt.text(0.02 + thresholds[loc], precisions[loc], '임계값 : {:.3f}'.format(thresholds[loc]), size = 15)
    
    start, end = plt.xlim()
    plt.xticks(np.round(np.arange(start, end, 0.1), 2), size = 15)
    plt.xlabel('Threshold value', size = 15); plt.ylabel('Precision and Recall value', size = 15)
    plt.legend()
    plt.rc('legend', fontsize = 15)
    plt.rc('ytick', labelsize = 15)
    plt.show()
    

# 임계값 조정 함수
def get_clf_eval_thres(y_test, pred_po, threshold, f1_show=False, auc_show=False):
    eval_df = pd.DataFrame()
    
    for thres in threshold:
        # threshold에 따른 예측 분류 값
        binarizer = Binarizer(threshold = thres)
        binarizer.fit(pred_po)
        thres_pred = binarizer.transform(pred_po)
        
        # 평가지표  
        accuracy = accuracy_score(y_test, thres_pred)
        precision = precision_score(y_test, thres_pred)
        recall = recall_score(y_test, thres_pred)
        f1 = f1_score(y_test, thres_pred)
        auc = roc_auc_score(y_test, pred_po)
        
        # 데이터 프레임 형태
        eval_lst = np.array([accuracy, precision, recall, f1, auc]).reshape(-1,1)
        temp = pd.DataFrame(eval_lst, columns=[thres], 
                            index = ["정확도", "정밀도", "재현율", "F1스코어", "AUC"])
        eval_df = pd.concat([eval_df,temp], axis=1)
        
    eval_df.columns.names = ["임계값"]
    
    if f1_show == False:
        eval_df.drop("F1스코어", axis=0, inplace=True)
        
    if auc_show == False:
        eval_df.drop("AUC", axis=0, inplace=True)
        
    return round(eval_df, 4)


sample = pd.read_csv('C:/k_digital/source/data/open/sample_submission.csv')
sample


test = pd.read_csv('C:/k_digital/source/data/open/test.csv')
test


train = pd.read_csv('C:/k_digital/source/data/open/train.csv')
train


ID = train['ID']


train['COMPONENT_ARBITRARY'].value_counts()


train.groupby(['COMPONENT_ARBITRARY', 'YEAR'])['Y_LABEL'].value_counts()


oil_info = pd.read_csv('C:/k_digital/source/data/open/data_info.csv')
oil_info


oil_na = pd.DataFrame(train.isna().sum(), columns = ['counts'])
oil_na['percent'] = oil_na['counts'] / len(train) * 100
oil_na = oil_na.reset_index()
oil_na




# 결측치 정도를 시각화
plt.figure(figsize = (20, 20))
msno.matrix(train)
plt.show()


# import pandas_profiling
# profile_report = pandas_profiling.ProfileReport(train)
# profile_report


U = train[['U4', 'U6', 'U14', 'U20', 'U25', 'U50', 'U75', 'U100', 'V40', 'V100', 'Y_LABEL']]
for i in U:
    print(U[U[i].isna() == True]['Y_LABEL'].value_counts(), '\n')

print('----------------------------------------------------------')

for i in U:
    print(U[U[i].isna() == False]['Y_LABEL'].value_counts(), '\n')


for i in U:
    print(i)
    print(U[i].value_counts(), '\n')


train['FUEL'].isna().value_counts()


train[train['FUEL'].isna() == False]['Y_LABEL'].value_counts()


train['FTBN'].value_counts()


sns.heatmap(U.corr(), annot = True, fmt = '0.1f', cmap = 'Blues')



target_count = pd.DataFrame(train['Y_LABEL'].value_counts()).reset_index()
sns.barplot(x = target_count['index'], y = target_count['Y_LABEL'], palette = 'deep')


train  = train[['COMPONENT_ARBITRARY', 'ANONYMOUS_1', 'YEAR' , 'ANONYMOUS_2', 
   'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', 
   'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN', 'Y_LABEL']]
train


categorical_features = ['COMPONENT_ARBITRARY', 'YEAR']
# Inference(실제 진단 환경)에 사용하는 컬럼
test_stage_features = ['COMPONENT_ARBITRARY', 'ANONYMOUS_1', 'YEAR' , 'ANONYMOUS_2', 'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', 'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN']


from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
for col in categorical_features:    
    train[col] = le.fit_transform(train[col])



train


train['CO'].value_counts()


train['Y_LABEL'].value_counts()


msno.matrix(train)
plt.show()


from sklearn.preprocessing import power_transform
scaled = power_transform(train.drop(['COMPONENT_ARBITRARY', 'YEAR', 'Y_LABEL'], axis = 1), method='yeo-johnson', standardize=False)
columns = ['ANONYMOUS_1', 'ANONYMOUS_2', 
   'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', 
   'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN']
scaled = pd.DataFrame(scaled, columns = columns)
scaled.head(10)


# from sklearn.preprocessing import StandardScaler
# ss = StandardScaler()
# scaled = ss.fit_transform(train.drop(['COMPONENT_ARBITRARY', 'YEAR', 'Y_LABEL'], axis = 1))
# columns = ['ANONYMOUS_1', 'ANONYMOUS_2', 
#    'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', 
#    'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN']
# scaled = pd.DataFrame(scaled, columns = columns)
# scaled.head()


onehot = train[['COMPONENT_ARBITRARY', 'YEAR']]
scaled = pd.concat([onehot, scaled], axis = 1)
scaled


scaled.hist(bins = 70, figsize = (15, 15))
plt.show()


sns.heatmap(scaled.corr(), annot = True, fmt = '0.1f', cmap = 'Blues')


from sklearn.model_selection import train_test_split


X_train, X_test, y_train, y_test = train_test_split(scaled, train['Y_LABEL'], test_size = 0.2, random_state = 2022, stratify = train['Y_LABEL'])


from imblearn.under_sampling import NearMiss

nearmiss=NearMiss()
under_X,under_y = nearmiss.fit_resample(X_train, y_train)
print("NearMiss 적용 전 학습용 피처/레이블 데이터 세트 : ", X_train.shape, y_train.shape)
print('NearMiss 적용 후 학습용 피처/레이블 데이터 세트 :', under_X.shape, under_y.shape)
print('NearMiss 적용 후 값의 분포 :\n',pd.Series(under_y).value_counts())


from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_over, y_train_over = smote.fit_resample(X_train, y_train)
print("SMOTE 적용 전 학습용 피처/레이블 데이터 세트 : ", X_train.shape, y_train.shape)
print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트 :', X_train_over.shape, y_train_over.shape)
print('SMOTE 적용 후 값의 분포 :\n',pd.Series(y_train_over).value_counts())


import sklearn.svm as svm
import sklearn.metrics as mt

svm_clf =svm.SVC(kernel = 'rbf', random_state=100, probability=True, C = 0.1, gamma = 10)

# 변환된 X로 교차검증

svm_clf.fit(X_train, y_train)



pred = svm_clf.predict(X_test)
pred_proba = svm_clf.predict_proba(X_test)[:, 1]
get_clf_eval(y_test ,pred, pred_proba)
print('macro f1 score : ', f1_score(y_test, pred, average = 'macro'))


help(MLPClassifier)


from sklearn.neural_network import MLPClassifier
import mglearn


mlp = MLPClassifier(hidden_layer_sizes=(100, ), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', 
                    learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=1000, 
                    shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, 
                    momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, 
                    beta_1=0.9, beta_2=0.999, epsilon=1e-08).fit(X_train, y_train)

pred = mlp.predict(X_test)
pred_proba = mlp.predict_proba(X_test)[:, 1]
get_clf_eval(y_test, pred, pred_proba)
print('macro f1 score : ', f1_score(y_test, pred, average = 'macro'))


precision_recall_curve_plot(y_test, pred_proba)


print('임계값 : ', 0.159)
binarizer = Binarizer(threshold = 0.159)
thres_pred = binarizer.fit_transform(pred_proba.reshape(-1,1))

get_clf_eval(y_test, thres_pred, pred_proba.reshape(-1,1))
print('Macro f1 socre : ', f1_score(y_test, thres_pred, average='macro'))


from sklearn.metrics import f1_score
from sklearn.model_selection import cross_validate
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators = 500, max_depth = 16, n_jobs = -1,random_state = 2022)
rf.fit(X_train_over, y_train_over)
scores = cross_validate(rf, X_train_over, y_train_over ,return_train_score = True) # return_train_score : 훈련세트와 테스트데이터 점수 둘 다 출력
pred = rf.predict(X_test)
accuracy = accuracy_score(y_test, pred)

print('훈련테스트 데이터 : {:.4f}, 테스트데이터 점수 : {:.4f}'.format(np.mean(scores['train_score']), np.mean(scores['test_score'])))
print('랜덤 포레스트 정확도 : {:.4f}'.format(accuracy))



pred_proba = rf.predict_proba(X_test)[:, 1]
get_clf_eval(y_test, pred, pred_proba)
print('Macro f1 score : ', f1_score(y_test, pred, average='macro'))



precision_recall_curve_plot(y_test, pred_proba)


print('임계값 : ', 0.515)
binarizer = Binarizer(threshold = 0.515)
thres_pred = binarizer.fit_transform(pred_proba.reshape(-1,1))

get_clf_eval(y_test, thres_pred, pred_proba.reshape(-1,1))
print('Macro f1 socre : ', f1_score(y_test, thres_pred, average='macro'))


pd.DataFrame(scores)


from sklearn.model_selection import GridSearchCV
rf = RandomForestClassifier(random_state = 2022)

params = {
    'max_depth':[2, 6, 10],   
    'min_samples_leaf':[1, 5, 9],
    'min_samples_split':[2, 6, 10]
}

gs = GridSearchCV(rf, param_grid = params, cv = 5, refit = True, n_jobs = -1) # n_jobs는 실행 코어수 조절(-1을 주면 모든 코어 사용)
gs.fit(X_train_over, y_train_over)


# 그리드 서치를 사용한 모델의 최적의 파라미터값
model = gs.best_estimator_
print(model.score(X_train_over, y_train_over))
print(model.score(X_test, y_test))


# 그리드 서치를 통해 찾은 최적의 매개변수
print(gs.best_estimator_)
print(gs.best_params_)
print(gs.best_score_)


rf = RandomForestClassifier(n_estimators=300, max_depth = 10, min_samples_leaf = 1, min_samples_split = 2, n_jobs = -1,random_state = 2022)
rf.fit(X_train_over, y_train_over)
pred = rf.predict(X_test)
pred_proba = rf.predict_proba(X_test)[:, 1]
scores = cross_validate(rf, X_train_over, y_train_over ,return_train_score = True) # return_train_score : 훈련세트와 테스트데이터 점수 둘 다 출력
accuracy = accuracy_score(y_test, rf_pred)

print('훈련테스트 데이터 : {:.4f}, 테스트데이터 점수 : {:.4f}'.format(np.mean(scores['train_score']), np.mean(scores['test_score'])))
print('랜덤 포레스트 정확도 : {:.4f}'.format(accuracy))
print('Macro f1 score : ', f1_score(y_test, pred, average='macro'))
get_clf_eval(y_test, pred, pred_proba.reshape(-1,1))


precision_recall_curve_plot(y_test, pred_proba)


print('임계값 : ', 0.493)
binarizer = Binarizer(threshold = 0.493)
thres_pred = binarizer.fit_transform(pred_proba.reshape(-1,1))

get_clf_eval(y_test, thres_pred, pred_proba.reshape(-1,1))
print('Macro f1 socre : ', f1_score(y_test, thres_pred, average='macro'))





from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve

from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import Binarizer
from xgboost import XGBClassifier
xgb= XGBClassifier()



#필요한 라이브러리 임포트
from xgboost import XGBClassifier

#XGBoost 정의
#파라미터는 이전 글을 참고하여 grid 설정(dict 형태)
xgb= XGBClassifier()

xgb_param_grid={
    'n_estimators' : [100,200,300,400,500],
    'learning_rate' : [0.01,0.05,0.1,0.15],
    'max_depth' : [3,5,7,10,15],
    'gamma' : [0,1,2,3],
    'colsample_bytree' : [0.8,0.9],
    
}

#score종류는 acc,f1,f1_micro,f1_macro등 원하는걸로 설정)
#여기서 설정 파라미터의 갯수(총 4000개의 조합이므로 4000번의 학습이 돌아감)
xgb_grid=GridSearchCV(xgb, param_grid = xgb_param_grid, scoring="f1_macro", n_jobs=-1, verbose = 2)
xgb_grid.fit(X_train, y_train)

#best f1_macro 수치와 best parameter확인
print("best f1_macro : {0: .4f}".format(xgb_grid.best_score_))
print("best param : ",xgb_grid.best_params_)

#dataframe으로 랭킹순보기
result_df = pd.DataFrame(xgb_grid.cv_results_)
result_df.sort_values(by=['rank_test_score'],inplace=True)

#plot
result_df[['params','mean_test_score','rank_test_score']].head(10)


aaa = xgb_grid.best_estimator_
aaa


xgb_pred = aaa.predict(X_test)
xgb_pred


xgb_pred_proba = aaa.predict_proba(X_test)[:, 1]
xgb_pred_proba


get_clf_eval(y_test, xgb_pred, xgb_pred_proba)


print('Macro f1 socre : ', f1_score(y_test, rf_pred, average='macro'))


print('훈련세트 ', aaa.score(X_train, y_train))
print(aaa.score(X_test, y_test))


param = xgb_grid.cv_results_['params']
param[0]



print(aaa.feature_importances_)


#feature 중요도도 그려볼 수 있다. 
from xgboost import plot_importance
import matplotlib.pyplot as plt
get_ipython().run_line_magic("matplotlib", " inline")

fig, ax = plt.subplots(figsize=(11, 12))

# 사이킷런 래퍼 클래스를 입력해도 무방. 
plot_importance(aaa, ax=ax)
plt.rc('font', size=10)        # 기본 폰트 크기
plt.rc('axes', labelsize=10)   # x,y축 label 폰트 크기
plt.rc('xtick', labelsize=10)  # x축 눈금 폰트 크기 
plt.rc('ytick', labelsize=10)  # y축 눈금 폰트 크기
plt.rc('legend', fontsize = 20)
plt.show()


help(XGBClassifier())


from xgboost import XGBClassifier
from hyperopt import hp

# max_depth는 5에서 15까지 1간격으로 , min_child_weight는 1에서 6까지 1간격으로
# colsample_bytree는 0.5에서 0.95사이, learning_rate는 0.01에서 0.2사이 정규 분포된 갑승로 검색
xgb_search_space = {'max_depth' : hp.quniform('max_depth', 100, 160, 1),
                    'subsample' : hp.uniform('subsample', 0.7, 1),
                    'learning_rate' : hp.uniform('learning_rate', 0.01, 0.2)
                   }


from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold



# fmim()에서 호출 시 search_space 값으로 NGBClassifier 교차 검증 학습 후 -1 * roc_auc 평균 값을 반환.
def objective_func(search_space):
    xgb_clf = XGBClassifier(n_estimators = 300,
                            max_depth = int(search_space['max_depth']),
                            subsample = search_space['subsample'],
                            learning_rate = search_space['learning_rate'],
                            objective = 'binary:logistic'
                           )
    
    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list
    roc_auc_list = []
    
    # 3개 k-fold 방식 적용
    skf = StratifiedKFold(n_splits=5, shuffle = True)
    # X_train을 다시 학습과 검증용 데이터로 분리
    for tr_index, val_index in skf.split(X_train, y_train):
        #kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리
        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]
        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]
        
        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 LGBMClassifier 학습 수행
        xgb_clf.fit(X_tr, y_tr, early_stopping_rounds = 30, eval_metric = 'logloss',
                    eval_set = [(X_tr, y_tr), (X_val, y_val)])
        
        # 1로 예측환 확률값 추출 후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값을 담음
        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])
        roc_auc_list.append(score)

    # 3개 k-fold로 계산된 roc_auc 값의 평균값을 반환하되, 
    # hyperOpt는 목적함수의 최솟값을 위한 입력값을 반환하므로 -1을 곱한 뒤 반환.
    return -1 * np.mean(roc_auc_list)


from hyperopt import fmin, tpe, Trials

trials = Trials()

# fmin() 함수를 호출, max_evals 지정된 횟수만큼 반복 후 목적함수의 최솟값을 가지는 최적 입력값 추출
best = fmin(fn = objective_func,
           space = xgb_search_space,
           algo = tpe.suggest,
           max_evals = 50,
            trials = trials, rstate = np.random.default_rng(seed = 30)
           )

print('best :', best)


xgb = XGBClassifier(n_estimators=500,
                   max_depth = int(best['max_depth']),
                    subsample = round(best['subsample'], 5),
                    learning_rate = round(best['learning_rate'], 5)
                   )

xgb.fit(X_train, y_train)

Y_preds = xgb.predict(X_test)
Y_pred_proba = xgb.predict_proba(X_test)[:, 1]


get_clf_eval(y_test, Y_preds, Y_pred_proba)
print('Macro f1 socre : ', f1_score(y_test, Y_preds, average='macro'))
print('Micro f1 socre : ', f1_score(y_test, Y_preds, average='micro'))


from xgboost import XGBClassifier
from hyperopt import hp

# max_depth는 5에서 15까지 1간격으로 , min_child_weight는 1에서 6까지 1간격으로
# colsample_bytree는 0.5에서 0.95사이, learning_rate는 0.01에서 0.2사이 정규 분포된 갑승로 검색
xgb_search_space = {'max_depth' : hp.quniform('max_depth', 100, 160, 1),
                    'subsample' : hp.uniform('subsample', 0.7, 1),
                    'learning_rate' : hp.uniform('learning_rate', 0.001, 0.2)
                   }


# fmim()에서 호출 시 search_space 값으로 NGBClassifier 교차 검증 학습 후 -1 * roc_auc 평균 값을 반환.
def objective_func(search_space):
    xgb_clf = XGBClassifier(n_estimators = 100,
                            max_depth = int(search_space['max_depth']),
                            subsample = search_space['subsample'],
                            learning_rate = search_space['learning_rate'],
                            objective = 'binary:logistic'
                           )
    
    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list
    roc_auc_list = []
    
    # 3개 k-fold 방식 적용
    skf = StratifiedKFold(n_splits=3, shuffle = True)
    # X_train을 다시 학습과 검증용 데이터로 분리
    for tr_index, val_index in skf.split(X_train_over, y_train_over):
        #kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리
        X_tr, y_tr = X_train_over.iloc[tr_index], y_train_over.iloc[tr_index]
        X_val, y_val = X_train_over.iloc[val_index], y_train_over.iloc[val_index]
        
        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 LGBMClassifier 학습 수행
        xgb_clf.fit(X_tr, y_tr, early_stopping_rounds = 30, eval_metric = 'logloss',
                    eval_set = [(X_tr, y_tr), (X_val, y_val)])
        
        # 1로 예측환 확률값 추출 후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값을 담음
        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])
        roc_auc_list.append(score)

    # 3개 k-fold로 계산된 roc_auc 값의 평균값을 반환하되, 
    # hyperOpt는 목적함수의 최솟값을 위한 입력값을 반환하므로 -1을 곱한 뒤 반환.
    return -1 * np.mean(roc_auc_list)


from hyperopt import fmin, tpe, Trials

trials = Trials()

# fmin() 함수를 호출, max_evals 지정된 횟수만큼 반복 후 목적함수의 최솟값을 가지는 최적 입력값 추출
best = fmin(fn = objective_func,
           space = xgb_search_space,
           algo = tpe.suggest,
           max_evals = 50,
            trials = trials, rstate = np.random.default_rng(seed = 30)
           )

print('best :', best)



xgb = XGBClassifier(n_estimators=500,
                   max_depth = int(best['max_depth']),
                    subsample = round(best['subsample'], 5),
                    learning_rate = round(best['learning_rate'], 5)
                   )

xgb.fit(X_train_over, y_train_over)

Y_preds = xgb.predict(X_test)
Y_pred_proba = xgb.predict_proba(X_test)[:, 1]


get_clf_eval(y_test, Y_preds, Y_pred_proba)
print('Macro f1 socre : ', f1_score(y_test, Y_preds, average='macro'))
print('Micro f1 socre : ', f1_score(y_test, Y_preds, average='micro'))


from sklearn.metrics import f1_score
from sklearn.model_selection import cross_validate
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier


from ngboost import NGBClassifier
from sklearn.metrics import mean_squared_error

ngb = NGBClassifier(n_estimators=500).fit(under_X, under_y)
Y_preds = ngb.predict(X_test)
Y_pred_proba = ngb.predict_proba(X_test)[:, 1]

# test Mean Squared Error
test_MSE = mean_squared_error(Y_preds, y_test)
print('Test MSE', test_MSE)


get_clf_eval(y_test, Y_preds, Y_pred_proba)
print('Macro f1 socre : ', f1_score(y_test, Y_preds, average='macro'))


help(NGBClassifier())


ngb = NGBClassifier(n_estimators=500).fit(X_train, y_train)
Y_preds = ngb.predict(X_test)
Y_pred_proba = ngb.predict_proba(X_test)[:, 1]




get_clf_eval(y_test, Y_preds, Y_pred_proba)
print('Macro f1 socre : ', f1_score(y_test, Y_preds, average='macro'))


from lightgbm import LGBMClassifier
from hyperopt import hp

# max_depth는 5에서 15까지 1간격으로 , min_child_weight는 1에서 6까지 1간격으로
# colsample_bytree는 0.5에서 0.95사이, learning_rate는 0.01에서 0.2사이 정규 분포된 갑승로 검색
lgbm_search_space = {'num_leaves' : hp.quniform('num_leaves', 32, 64, 1),
                     'max_depth' : hp.quniform('max_depth', 100, 160, 1),
                     'min_child_samples' : hp.quniform('min_child_samples', 60, 100, 1),
                    'subsample' : hp.uniform('subsample', 0.7, 1),
                    'learning_rate' : hp.uniform('learning_rate', 0.01, 0.2)
                   }


from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold



# fmim()에서 호출 시 search_space 값으로 NGBClassifier 교차 검증 학습 후 -1 * roc_auc 평균 값을 반환.
def objective_func(search_space):
    lgbm_clf = LGBMClassifier(n_estimators = 500,
                            num_leaves = int(search_space['num_leaves']),
                            max_depth = int(search_space['max_depth']),
                            min_child_samples = int(search_space['min_child_samples']),
                            subsample = search_space['subsample'],
                            learning_rate = search_space['learning_rate']
                           )
    
    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list
    roc_auc_list = []
    
    # 3개 k-fold 방식 적용
    skf = StratifiedKFold(n_splits=3)
    # X_train을 다시 학습과 검증용 데이터로 분리
    for tr_index, val_index in skf.split(X_train, y_train):
        #kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리
        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]
        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]
        
        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 LGBMClassifier 학습 수행
        lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds = 30, eval_metric = 'logloss',
                    eval_set = [(X_tr, y_tr), (X_val, y_val)])
        
        # 1로 예측환 확률값 추출 후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값을 담음
        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, 1])
        roc_auc_list.append(score)

    # 3개 k-fold로 계산된 roc_auc 값의 평균값을 반환하되, 
    # hyperOpt는 목적함수의 최솟값을 위한 입력값을 반환하므로 -1을 곱한 뒤 반환.
    return -1 * np.mean(roc_auc_list)


from hyperopt import fmin, tpe, Trials

trials = Trials()

# fmin() 함수를 호출, max_evals 지정된 횟수만큼 반복 후 목적함수의 최솟값을 가지는 최적 입력값 추출
best = fmin(fn = objective_func,
           space = lgbm_search_space,
           algo = tpe.suggest,
           max_evals = 50,
            trials = trials, rstate = np.random.default_rng(seed = 30)
           )

print('best :', best)


ngb = LGBMClassifier(n_estimators=50000, 
                              num_leaves = 128, 
                              subsample=0.6,
                              colsample_bytree=0.7,
                              reg_lambda=15,
                              random_state=20)
ngb.fit(X_train, y_train)

Y_preds = ngb.predict(X_test)
Y_pred_proba = ngb.predict_proba(X_test)[:, 1]


get_clf_eval(y_test, Y_preds, Y_pred_proba)
print('Macro f1 socre : ', f1_score(y_test, Y_preds, average='macro'))


ngb = LGBMClassifier(n_estimators=500, num_leaves = int(best['num_leaves']),
                   max_depth = int(best['max_depth']),
                    min_child_samples = int(best['min_child_samples']),
                    subsample = round(best['subsample'], 5),
                    learning_rate = round(best['learning_rate'], 5)
                   )

ngb.fit(X_train, y_train)

Y_preds = ngb.predict(X_test)
Y_pred_proba = ngb.predict_proba(X_test)[:, 1]


get_clf_eval(y_test, Y_preds, Y_pred_proba)
print('Macro f1 socre : ', f1_score(y_test, Y_preds, average='macro'))


from lightgbm import LGBMClassifier
from hyperopt import hp

# max_depth는 5에서 15까지 1간격으로 , min_child_weight는 1에서 6까지 1간격으로
# colsample_bytree는 0.5에서 0.95사이, learning_rate는 0.01에서 0.2사이 정규 분포된 갑승로 검색
lgbm_search_space = {'num_leaves' : hp.quniform('num_leaves', 32, 64, 1),
                     'max_depth' : hp.quniform('max_depth', 100, 160, 1),
                     'min_child_samples' : hp.quniform('min_child_samples', 60, 100, 1),
                    'subsample' : hp.uniform('subsample', 0.7, 1),
                    'learning_rate' : hp.uniform('learning_rate', 0.001, 0.2)
                   }


from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold



# fmim()에서 호출 시 search_space 값으로 NGBClassifier 교차 검증 학습 후 -1 * roc_auc 평균 값을 반환.
def objective_func(search_space):
    lgbm_clf = LGBMClassifier(n_estimators = 300,
                            num_leaves = int(search_space['num_leaves']),
                            max_depth = int(search_space['max_depth']),
                            min_child_samples = int(search_space['min_child_samples']),
                            subsample = search_space['subsample'],
                            learning_rate = search_space['learning_rate']
                           )
    
    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list
    roc_auc_list = []
    
    # 3개 k-fold 방식 적용
    skf = StratifiedKFold(n_splits=3)
    # X_train을 다시 학습과 검증용 데이터로 분리
    for tr_index, val_index in skf.split(X_train_over, y_train_over):
        #kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리
        X_tr, y_tr = X_train_over.iloc[tr_index], y_train_over.iloc[tr_index]
        X_val, y_val = X_train_over.iloc[val_index], y_train_over.iloc[val_index]
        
        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 LGBMClassifier 학습 수행
        lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds = 30, eval_metric = 'logloss',
                    eval_set = [(X_tr, y_tr), (X_val, y_val)])
        
        # 1로 예측환 확률값 추출 후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값을 담음
        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, 1])
        roc_auc_list.append(score)

    # 3개 k-fold로 계산된 roc_auc 값의 평균값을 반환하되, 
    # hyperOpt는 목적함수의 최솟값을 위한 입력값을 반환하므로 -1을 곱한 뒤 반환.
    return -1 * np.mean(roc_auc_list)


from hyperopt import fmin, tpe, Trials

trials = Trials()

# fmin() 함수를 호출, max_evals 지정된 횟수만큼 반복 후 목적함수의 최솟값을 가지는 최적 입력값 추출
best = fmin(fn = objective_func,
           space = lgbm_search_space,
           algo = tpe.suggest,
           max_evals = 50,
            trials = trials, rstate = np.random.default_rng(seed = 30)
           )

print('best :', best)


ngb = LGBMClassifier(n_estimators=500, num_leaves = int(best['num_leaves']),
                   max_depth = int(best['max_depth']),
                    min_child_samples = int(best['min_child_samples']),
                    subsample = round(best['subsample'], 5),
                    learning_rate = round(best['learning_rate'], 5)
                   )

ngb.fit(X_train_over, y_train_over)

Y_preds = ngb.predict(X_test)
Y_pred_proba = ngb.predict_proba(X_test)[:, 1]


get_clf_eval(y_test, Y_preds, Y_pred_proba)
print('Macro f1 socre : ', f1_score(y_test, Y_preds, average='macro'))


from sklearn.linear_model import LogisticRegression
from scipy.special import expit

#train_test_split data
lr = LogisticRegression()
lr.fit(X_train_over, y_train_over)

lr_cross = cross_val_predict(lr, X_test, y_test, cv=10)

print(lr.score(X_train_over, y_train_over))
print(lr.score(X_train_over, y_train_over))
print('Macro f1 socre : ', f1_score(y_test, lr_cross, average='macro'))


from sklearn.model_selection import GridSearchCV

params = {'solver' : ['liblinear', 'lbfgs'],
         'penalty' : ['l2', 'l1'],
          'C' : [0.01, 0.1, 1, 1, 5, 10]
         }
lr = LogisticRegression()
grid_lr = GridSearchCV(lr, param_grid = params, scoring = 'f1_macro', cv = 10)
grid_lr.fit(X_train_over, y_train_over)
print('최적 하이퍼 파라미터 : {0}, 최적 평균 f1 점수 : {1}'.format(grid_lr.best_params_, grid_lr.best_score_))


model = grid_lr.best_estimator_
preds = model.predict(X_test)
pred_proba = model.predict_proba(X_test)[:, 1]
print(model.score(X_train_over, y_train_over))
print(model.score(X_test, y_test))
get_clf_eval(y_test, preds, pred_proba)
print('Macro f1 socre : ', f1_score(y_test, preds, average='macro'))


# 정밀도와 재현율 곡선
precision_recall_curve_plot(y_test, pred_proba)


params = {'solver' : ['liblinear', 'lbfgs'],
         'penalty' : ['l2', 'l1'],
          'C' : [0.01, 0.1, 1, 1, 5, 10]
         }
lr = LogisticRegression()
grid_lr = GridSearchCV(lr, param_grid = params, scoring = 'f1_macro', cv = 10)
grid_lr.fit(X_train, y_train)
print('최적 하이퍼 파라미터 : {0}, 최적 평균 f1 점수 : {1}'.format(grid_lr.best_params_, grid_lr.best_score_))


model = grid_lr.best_estimator_
preds = model.predict(X_test)
pred_proba = model.predict_proba(X_test)[:, 1]
print(model.score(X_train, y_train))
print(model.score(X_test, y_test))
get_clf_eval(y_test, preds, pred_proba)
print('Macro f1 socre : ', f1_score(y_test, preds, average='macro'))


# 혼돈 행렬 시각화
cm = confusion_matrix(y_test, preds)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot = True, annot_kws = {'size':20}, fmt = '0.0f', cmap='Blues')
plt.xlabel('Predicted', size = 20)
plt.ylabel('Actual', size = 20)
plt.text(0.45, 0.4, 'TN', color = 'w', fontsize = 20)
plt.text(1.45, 0.4, 'FP', color = 'black', fontsize = 20)
plt.text(0.45, 1.4, 'FN', color = 'black', fontsize = 20)
plt.text(1.45, 1.4, 'TP', color = 'black', fontsize = 20)
plt.show()


y_test.value_counts()


from sklearn.model_selection import GridSearchCV
rf = RandomForestClassifier(random_state = 2022)

params = {
    'max_depth':[8, 16, 24],   
    'min_samples_leaf':[1, 6, 12],
    'min_samples_split':[2, 8, 16]
}

gs = GridSearchCV(rf, param_grid = params, cv = 10, refit = True, n_jobs = -1) # n_jobs는 실행 코어수 조절(-1을 주면 모든 코어 사용)
gs.fit(X_train_over, y_train_over)
print('최적 하이퍼 파라미터 : {0}, 최적 평균 f1 점수 : {1}'.format(gs.best_params_, gs.best_score_))


model = gs.best_estimator_
preds = model.predict(X_test)
pred_proba = model.predict_proba(X_test)[:, 1]
print('훈련데이터 점수 : ',model.score(X_train_over, y_train_over))
print('테스트데이터 점수 : ', model.score(X_test, y_test), '\n')
get_clf_eval(y_test, preds, pred_proba)
print('Macro f1 socre : ', f1_score(y_test, preds, average='macro'))


# 정밀도와 재현율 곡선
precision_recall_curve_plot(y_test, pred_proba)


from sklearn.preprocessing import Binarizer

thresholds = np.arange(0, 1, 0.01)

for custom_threshold in thresholds:
    pred_proba = gs.predict_proba(X_test)
   
    
    binarizer = Binarizer(threshold = custom_threshold)
    thres_pred = binarizer.fit_transform(pred_proba[:,1].reshape(-1,1))
    f1 = f1_score(y_test, thres_pred)
    get_clf_eval(y_test, thres_pred, pred_proba[:,1].reshape(-1,1))
    print('Macro f1 socre : ', f1_score(y_test, thres_pred, average='macro'))


binarizer = Binarizer(threshold = 0.381)
thres_pred = binarizer.fit_transform(pred_proba[:, 1].reshape(-1,1))

get_clf_eval(y_test, thres_pred, pred_proba[:, 1].reshape(-1,1))
print('Macro f1 socre : ', f1_score(y_test, thres_pred, average='macro'))


import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


# 개별 ML 모델을 위한 Classifier 생성.
knn_clf  = KNeighborsClassifier(n_neighbors=3)
rf_clf = RandomForestClassifier(n_estimators = 100, max_depth = 8, 
                                min_samples_leaf=2, min_samples_split = 6)
dt_clf = DecisionTreeClassifier(max_depth = 3, min_samples_leaf =  9, min_samples_split =  2)
ada_clf = AdaBoostClassifier(n_estimators=100)

# 최종 Stacking 모델을 위한 Classifier생성. 
xgb_final = XGBClassifier(C=5, penalty = 'l2')

# 개별 모델들을 학습. 
knn_clf.fit(X_train, y_train)
rf_clf.fit(X_train , y_train)
dt_clf.fit(X_train , y_train)
ada_clf.fit(X_train, y_train)

# 학습된 개별 모델들이 각자 반환하는 예측 데이터 셋을 생성하고 개별 모델의 정확도 측정. 
knn_pred = knn_clf.predict(X_test)
rf_pred = rf_clf.predict(X_test)
dt_pred = dt_clf.predict(X_test)
ada_pred = ada_clf.predict(X_test)

print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_test, knn_pred)))
print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred)))
print('결정 트리 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))
print('에이다부스트 정확도: {0:.4f}'.format(accuracy_score(y_test, ada_pred)))
print('KNN macro macro f1 score : ', f1_score(y_test, knn_pred, average = 'macro'))
print('랜덤 포레스트  macro f1 score : ', f1_score(y_test, rf_pred, average = 'macro'))
print('결정 트리 macro f1 score : ', f1_score(y_test, dt_pred, average = 'macro'))
print('에이다부스트 macro f1 score : ', f1_score(y_test, ada_pred, average = 'macro'))


pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])

# transpose를 이용해 행과 열의 위치 교환. 컬럼 레벨로 각 알고리즘의 예측 결과를 피처로 만듦. 
pred = np.transpose(pred)

lr_final.fit(pred, y_test)
final = lr_final.predict(pred)
print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test , final)))


from sklearn.model_selection import KFold
from sklearn.metrics import mean_absolute_error
import re

# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. 
def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds ):
    # 지정된 n_folds값으로 KFold 생성.
    kf = KFold(n_splits=n_folds, shuffle=False)
    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 
    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))
    test_pred = np.zeros((X_test_n.shape[0],n_folds))

    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):
        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 
        X_tr = X_train_n[train_index] 
        y_tr = y_train_n[train_index] 
        X_te = X_train_n[valid_index]  

        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.
        model.fit(X_tr , y_tr)       
        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.
        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)
        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. 
        test_pred[:, folder_counter] = model.predict(X_test_n)
   
    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 
    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    

    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터
    return train_fold_pred , test_pred_mean

X_train_n = X_train.reset_index(drop=True).values
X_test_n = X_test.reset_index(drop=True).values
y_train_n = y_train.reset_index(drop=True).values

knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train_n, y_train_n, X_test_n, 7)
rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train_n, y_train_n, X_test_n, 7)
dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train_n, y_train_n, X_test_n,  7)    
ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train_n, y_train_n, X_test_n, 7)

Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)
Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)
print('원본 학습 피처 데이터 Shape:',X_train.shape, '원본 테스트 피처 Shape:',X_test.shape)
print('스태킹 학습 피처 데이터 Shape:', Stack_final_X_train.shape,
      '스태킹 테스트 피처 데이터 Shape:',Stack_final_X_test.shape)


Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)
Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)
print('원본 학습 피처 데이터 Shape:',X_train.shape, '원본 테스트 피처 Shape:',X_test.shape)
print('스태킹 학습 피처 데이터 Shape:', Stack_final_X_train.shape,
      '스태킹 테스트 피처 데이터 Shape:',Stack_final_X_test.shape)


lr_final.fit(Stack_final_X_train, y_train)
stack_final = lr_final.predict(Stack_final_X_test)

print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, stack_final)))
print('최종 메타 모델의 macro f1 score :', f1_score(y_test, stack_final, average = 'macro'))


train


categorical_features = ['COMPONENT_ARBITRARY', 'YEAR']



from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
for col in categorical_features:    
    test[col] = le.fit_transform(test[col])


test = test.drop('ID', axis = 1)


from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
scaled = ss.fit_transform(test.drop(['COMPONENT_ARBITRARY', 'YEAR'], axis = 1))
columns = ['ANONYMOUS_1', 'ANONYMOUS_2', 
   'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', 
   'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN']
scaled = pd.DataFrame(scaled, columns = columns)
scaled.head()


onehot = test[['COMPONENT_ARBITRARY', 'YEAR']]
scaled = pd.concat([onehot, scaled], axis = 1)
scaled


def NMAE(true, pred):
    score = np.mean(np.abs(true - pred) / true)
    return score


get_ipython().getoutput("pip install catboost==1.1.1")


from sklearn.model_selection import StratifiedKFold
from sklearn.utils import shuffle
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from ngboost import NGBClassifier


skf = StratifiedKFold(n_splits = 10, random_state = 42, shuffle = True) #총 15번의 fold 진행
n = 0 #x번째 fold인지 기록

fold_target_pred = []

for train_index, valid_index in skf.split(train, train['Y_LABEL']):
    n += 1
    
    val_pred_name = [] #validation pred model 이름 저장
    val_pred = []      #validation set pred 결과 저장
    target_pred = []   #test set pred 결과 저장
    
    train_X = np.array(train.drop("Y_LABEL", axis = 1)) #분배된 학습을 위해 만들어둔 Range feature 제거
    train_Y = np.array(train['Y_LABEL'])
    
    X_train, X_valid = train_X[train_index], train_X[valid_index]
    y_train, y_valid = train_Y[train_index], train_Y[valid_index]
    
    X_test = np.array(test)

    ### Create Model ###
    
    ###모델을 생성하고 집어넣으면 됩니다.
    
#     ### MLPRegressor ###
#     model = MLPRegressor(random_state = 42, activation = 'tanh')
#     model.fit(X_train, y_train) # 모델 학습
    
#     val_pred_name.append("MLPRegressor")      # 모델 이름 저장
#     val_pred.append(model.predict(X_valid))   # validation set pred 결과 저장
#     target_pred.append(model.predict(X_test)) # test set pred 결과 저장
    
    ### NGBRegressor ###
    model = NGBClassifier(random_state = 42, verbose = 0)
    model.fit(X_train, y_train)
    
    val_pred_name.append("NGBClassifier")      # 모델 이름 저장
    val_pred.append(model.predict(X_valid))   # validation set pred 결과 저장
    target_pred.append(model.predict(X_test)) # test set pred 결과 저장
    
    ### XGBRegressor ###
    model = XGBClassifier(random_state = 42,)
    model.fit(X_train, y_train)
    
    val_pred_name.append("XGBClassifier")      # 모델 이름 저장
    val_pred.append(model.predict(X_valid))   # validation set pred 결과 저장
    target_pred.append(model.predict(X_test)) # test set pred 결과 저장
    
    ### CatBoostRegressor ###
    model = CatBoostClassifier(iterations = 1000, verbose = 0, task_type="CPU", random_state = 42)
    model.fit(X_train, y_train)
    
    val_pred_name.append("CatBoostClassifier")      # 모델 이름 저장
    val_pred.append(model.predict(X_valid))   # validation set pred 결과 저장
    target_pred.append(model.predict(X_test)) # test set pred 결과 저장
    
    ### voting ###
    
    ### average validation pred ###
    preds = np.array(val_pred[0])
    for i in range(1, len(val_pred)):
        preds += val_pred[i]
    
    preds = preds/len(val_pred)
    
    ### average target pred ###
    target_preds = np.array(target_pred[0])
    for i in range(1, len(target_pred)):
        target_preds += target_pred[i]
    
    target_preds = target_preds/len(target_pred)
    
    fold_target_pred.append(target_preds) # append final target pred
    
    print("========== fold %d ==========" %(n))
    for i in range(len(val_pred)):
        print("%s model NMAE : %0.4f" %(val_pred_name[i], NMAE(y_valid, val_pred[i].astype(int))))
        
    print("==============================")
    print("Average NMAE %0.4f" %(NMAE(y_valid, preds.astype(int))))
    print("")


model = CatBoostClassifier(max_depth=12, learning_rate=0.15, loss_function='Logloss', task_type = 'CPU',
                          grow_policy = 'Lossguide', n_estimators=1500)

model.fit(X_train, y_train, eval_set=(X_test, y_test), plot=True)


pred  = model.predict(X_test)
pred_proba = model.predict_proba(X_test)[:, 1]
get_clf_eval(y_test, pred, pred_proba)


print('Macro f1 socre : ', f1_score(y_test, pred, average='macro'))


# 정밀도와 재현율 곡선
precision_recall_curve_plot(y_test, pred_proba)


model = CatBoostClassifier(max_depth=12, learning_rate=0.15, loss_function='Logloss', task_type = 'CPU',
                          grow_policy = 'Lossguide', n_estimators=1500)

model.fit(X_train_over, y_train_over, eval_set=(X_test, y_test), plot=True)


pred  = model.predict(X_test)
pred_proba = model.predict_proba(X_test)[:, 1]
get_clf_eval(y_test, pred, pred_proba)
print('Macro f1 socre : ', f1_score(y_test, pred, average='macro'))


# 정밀도와 재현율 곡선
precision_recall_curve_plot(y_test, pred_proba)


test


test = test.drop('ID', axis = 1)
test


categorical_features = ['COMPONENT_ARBITRARY', 'YEAR']
# Inference(실제 진단 환경)에 사용하는 컬럼
test_stage_features = ['COMPONENT_ARBITRARY', 'ANONYMOUS_1', 'YEAR' , 'ANONYMOUS_2', 'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', 'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN']


from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
for col in categorical_features:    
    test[col] = le.fit_transform(test[col])



from sklearn.preprocessing import power_transform
scaled = power_transform(test.drop(['COMPONENT_ARBITRARY', 'YEAR'], axis = 1), method='yeo-johnson', standardize=False)
columns = ['ANONYMOUS_1', 'ANONYMOUS_2', 
   'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', 
   'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN']
scaled = pd.DataFrame(scaled, columns = columns)
scaled.head(10)


onehot = test[['COMPONENT_ARBITRARY', 'YEAR']]
scaled = pd.concat([onehot, scaled], axis = 1)
scaled


pred_proba = rf.predict_proba(scaled)[:, 1]
binarizer = Binarizer(threshold = 0.515)
thres_pred = binarizer.fit_transform(pred_proba.reshape(-1,1))


thres_pred = thres_pred.astype('int64')


sample['Y_LABEL'] = thres_pred


sample.to_csv('./sample.csv', index = False)


pd.read_csv('./sample.csv')



