{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14장 모델의 성능 향상시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\"https://raw.githubusercontent.com/taehojo/taehojo.github.io/master/assets/images/linktocolab.png\" align=\"left\"/> ](https://colab.research.google.com/github/taehojo/deeplearning/blob/master/colab/ch14-colab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터의 확인과 검증셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T06:04:51.874959Z",
     "start_time": "2022-12-08T06:04:43.180780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 입력합니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 데이터를 미리 보겠습니다.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T06:04:51.922538Z",
     "start_time": "2022-12-08T06:04:51.909866Z"
    }
   },
   "outputs": [],
   "source": [
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T06:04:55.258793Z",
     "start_time": "2022-12-08T06:04:51.987185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                390       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                372       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Ananconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 34ms/step - loss: 0.3880 - accuracy: 0.8319 - val_loss: 0.3394 - val_accuracy: 0.8554\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8483 - val_loss: 0.3208 - val_accuracy: 0.8600\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3121 - accuracy: 0.8809 - val_loss: 0.3013 - val_accuracy: 0.8846\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2940 - accuracy: 0.8820 - val_loss: 0.2857 - val_accuracy: 0.8954\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2783 - accuracy: 0.9043 - val_loss: 0.2715 - val_accuracy: 0.9046\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2633 - accuracy: 0.9081 - val_loss: 0.2566 - val_accuracy: 0.9108\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2491 - accuracy: 0.9187 - val_loss: 0.2430 - val_accuracy: 0.9138\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2361 - accuracy: 0.9217 - val_loss: 0.2299 - val_accuracy: 0.9208\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2258 - accuracy: 0.9274 - val_loss: 0.2213 - val_accuracy: 0.9231\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2185 - accuracy: 0.9281 - val_loss: 0.2159 - val_accuracy: 0.9254\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2131 - accuracy: 0.9294 - val_loss: 0.2120 - val_accuracy: 0.9254\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2091 - accuracy: 0.9299 - val_loss: 0.2091 - val_accuracy: 0.9269\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2055 - accuracy: 0.9302 - val_loss: 0.2052 - val_accuracy: 0.9269\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2021 - accuracy: 0.9323 - val_loss: 0.2026 - val_accuracy: 0.9308\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1991 - accuracy: 0.9338 - val_loss: 0.1992 - val_accuracy: 0.9323\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1973 - accuracy: 0.9343 - val_loss: 0.1979 - val_accuracy: 0.9323\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1935 - accuracy: 0.9353 - val_loss: 0.1968 - val_accuracy: 0.9292\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1908 - accuracy: 0.9364 - val_loss: 0.1925 - val_accuracy: 0.9346\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1882 - accuracy: 0.9376 - val_loss: 0.1907 - val_accuracy: 0.9362\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1857 - accuracy: 0.9371 - val_loss: 0.1883 - val_accuracy: 0.9362\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1833 - accuracy: 0.9389 - val_loss: 0.1872 - val_accuracy: 0.9338\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1831 - accuracy: 0.9374 - val_loss: 0.1867 - val_accuracy: 0.9338\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1793 - accuracy: 0.9382 - val_loss: 0.1821 - val_accuracy: 0.9354\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1760 - accuracy: 0.9405 - val_loss: 0.1802 - val_accuracy: 0.9385\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1739 - accuracy: 0.9405 - val_loss: 0.1778 - val_accuracy: 0.9377\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1720 - accuracy: 0.9423 - val_loss: 0.1760 - val_accuracy: 0.9369\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1698 - accuracy: 0.9420 - val_loss: 0.1744 - val_accuracy: 0.9385\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1674 - accuracy: 0.9420 - val_loss: 0.1713 - val_accuracy: 0.9392\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1658 - accuracy: 0.9459 - val_loss: 0.1705 - val_accuracy: 0.9415\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1623 - accuracy: 0.9446 - val_loss: 0.1643 - val_accuracy: 0.9415\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1584 - accuracy: 0.9466 - val_loss: 0.1638 - val_accuracy: 0.9415\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1585 - accuracy: 0.9477 - val_loss: 0.1603 - val_accuracy: 0.9431\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1546 - accuracy: 0.9471 - val_loss: 0.1607 - val_accuracy: 0.9446\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1539 - accuracy: 0.9479 - val_loss: 0.1597 - val_accuracy: 0.9454\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1542 - accuracy: 0.9484 - val_loss: 0.1538 - val_accuracy: 0.9446\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1477 - accuracy: 0.9497 - val_loss: 0.1513 - val_accuracy: 0.9469\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1458 - accuracy: 0.9505 - val_loss: 0.1509 - val_accuracy: 0.9462\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1433 - accuracy: 0.9512 - val_loss: 0.1473 - val_accuracy: 0.9485\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1419 - accuracy: 0.9515 - val_loss: 0.1460 - val_accuracy: 0.9500\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1398 - accuracy: 0.9518 - val_loss: 0.1441 - val_accuracy: 0.9477\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1420 - accuracy: 0.9497 - val_loss: 0.1484 - val_accuracy: 0.9454\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1371 - accuracy: 0.9530 - val_loss: 0.1411 - val_accuracy: 0.9477\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1355 - accuracy: 0.9530 - val_loss: 0.1407 - val_accuracy: 0.9546\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1332 - accuracy: 0.9520 - val_loss: 0.1406 - val_accuracy: 0.9546\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1354 - accuracy: 0.9533 - val_loss: 0.1392 - val_accuracy: 0.9546\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1309 - accuracy: 0.9538 - val_loss: 0.1350 - val_accuracy: 0.9562\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1285 - accuracy: 0.9554 - val_loss: 0.1336 - val_accuracy: 0.9546\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1268 - accuracy: 0.9554 - val_loss: 0.1351 - val_accuracy: 0.9569\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1261 - accuracy: 0.9548 - val_loss: 0.1313 - val_accuracy: 0.9585\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1243 - accuracy: 0.9559 - val_loss: 0.1303 - val_accuracy: 0.9592\n"
     ]
    }
   ],
   "source": [
    "#학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25) # 0.8 x 0.25 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T06:04:55.462899Z",
     "start_time": "2022-12-08T06:04:55.356457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 967us/step - loss: 0.1194 - accuracy: 0.9585\n",
      "Test accuracy: 0.9584615230560303\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 업데이트하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 코드 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T06:05:11.300551Z",
     "start_time": "2022-12-08T06:05:10.457464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 30)                390       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 12)                372       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터를 입력합니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "#학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델의 저장 설정 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T06:05:24.467773Z",
     "start_time": "2022-12-08T06:05:20.854002Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Ananconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./data/model/all\\01-0.7462.hdf5\n",
      "\n",
      "Epoch 2: saving model to ./data/model/all\\02-0.7254.hdf5\n",
      "\n",
      "Epoch 3: saving model to ./data/model/all\\03-0.7585.hdf5\n",
      "\n",
      "Epoch 4: saving model to ./data/model/all\\04-0.7769.hdf5\n",
      "\n",
      "Epoch 5: saving model to ./data/model/all\\05-0.8015.hdf5\n",
      "\n",
      "Epoch 6: saving model to ./data/model/all\\06-0.8323.hdf5\n",
      "\n",
      "Epoch 7: saving model to ./data/model/all\\07-0.8446.hdf5\n",
      "\n",
      "Epoch 8: saving model to ./data/model/all\\08-0.8592.hdf5\n",
      "\n",
      "Epoch 9: saving model to ./data/model/all\\09-0.8885.hdf5\n",
      "\n",
      "Epoch 10: saving model to ./data/model/all\\10-0.9023.hdf5\n",
      "\n",
      "Epoch 11: saving model to ./data/model/all\\11-0.9123.hdf5\n",
      "\n",
      "Epoch 12: saving model to ./data/model/all\\12-0.9138.hdf5\n",
      "\n",
      "Epoch 13: saving model to ./data/model/all\\13-0.9185.hdf5\n",
      "\n",
      "Epoch 14: saving model to ./data/model/all\\14-0.9215.hdf5\n",
      "\n",
      "Epoch 15: saving model to ./data/model/all\\15-0.9231.hdf5\n",
      "\n",
      "Epoch 16: saving model to ./data/model/all\\16-0.9246.hdf5\n",
      "\n",
      "Epoch 17: saving model to ./data/model/all\\17-0.9254.hdf5\n",
      "\n",
      "Epoch 18: saving model to ./data/model/all\\18-0.9300.hdf5\n",
      "\n",
      "Epoch 19: saving model to ./data/model/all\\19-0.9285.hdf5\n",
      "\n",
      "Epoch 20: saving model to ./data/model/all\\20-0.9292.hdf5\n",
      "\n",
      "Epoch 21: saving model to ./data/model/all\\21-0.9323.hdf5\n",
      "\n",
      "Epoch 22: saving model to ./data/model/all\\22-0.9338.hdf5\n",
      "\n",
      "Epoch 23: saving model to ./data/model/all\\23-0.9354.hdf5\n",
      "\n",
      "Epoch 24: saving model to ./data/model/all\\24-0.9385.hdf5\n",
      "\n",
      "Epoch 25: saving model to ./data/model/all\\25-0.9408.hdf5\n",
      "\n",
      "Epoch 26: saving model to ./data/model/all\\26-0.9415.hdf5\n",
      "\n",
      "Epoch 27: saving model to ./data/model/all\\27-0.9415.hdf5\n",
      "\n",
      "Epoch 28: saving model to ./data/model/all\\28-0.9423.hdf5\n",
      "\n",
      "Epoch 29: saving model to ./data/model/all\\29-0.9423.hdf5\n",
      "\n",
      "Epoch 30: saving model to ./data/model/all\\30-0.9415.hdf5\n",
      "\n",
      "Epoch 31: saving model to ./data/model/all\\31-0.9423.hdf5\n",
      "\n",
      "Epoch 32: saving model to ./data/model/all\\32-0.9423.hdf5\n",
      "\n",
      "Epoch 33: saving model to ./data/model/all\\33-0.9423.hdf5\n",
      "\n",
      "Epoch 34: saving model to ./data/model/all\\34-0.9423.hdf5\n",
      "\n",
      "Epoch 35: saving model to ./data/model/all\\35-0.9431.hdf5\n",
      "\n",
      "Epoch 36: saving model to ./data/model/all\\36-0.9423.hdf5\n",
      "\n",
      "Epoch 37: saving model to ./data/model/all\\37-0.9431.hdf5\n",
      "\n",
      "Epoch 38: saving model to ./data/model/all\\38-0.9423.hdf5\n",
      "\n",
      "Epoch 39: saving model to ./data/model/all\\39-0.9438.hdf5\n",
      "\n",
      "Epoch 40: saving model to ./data/model/all\\40-0.9438.hdf5\n",
      "\n",
      "Epoch 41: saving model to ./data/model/all\\41-0.9438.hdf5\n",
      "\n",
      "Epoch 42: saving model to ./data/model/all\\42-0.9438.hdf5\n",
      "\n",
      "Epoch 43: saving model to ./data/model/all\\43-0.9438.hdf5\n",
      "\n",
      "Epoch 44: saving model to ./data/model/all\\44-0.9438.hdf5\n",
      "\n",
      "Epoch 45: saving model to ./data/model/all\\45-0.9438.hdf5\n",
      "\n",
      "Epoch 46: saving model to ./data/model/all\\46-0.9438.hdf5\n",
      "\n",
      "Epoch 47: saving model to ./data/model/all\\47-0.9438.hdf5\n",
      "\n",
      "Epoch 48: saving model to ./data/model/all\\48-0.9438.hdf5\n",
      "\n",
      "Epoch 49: saving model to ./data/model/all\\49-0.9438.hdf5\n",
      "\n",
      "Epoch 50: saving model to ./data/model/all\\50-0.9438.hdf5\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장의 조건을 설정합니다.\n",
    "modelpath=\"./data/model/all/{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, verbose=1)\n",
    "\n",
    "# 모델을 실행합니다. \n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25, verbose=0, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T06:05:24.669519Z",
     "start_time": "2022-12-08T06:05:24.563884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9438\n",
      "Test accuracy: 0.9438461661338806\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 그래프로 과적합 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T06:06:40.261275Z",
     "start_time": "2022-12-08T06:05:31.880817Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Ananconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    }
   ],
   "source": [
    "# 그래프 확인을 위한 긴 학습 (컴퓨터 환경에 따라 시간이 다소 걸릴수 있습니다)\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, verbose=0, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T06:06:40.370721Z",
     "start_time": "2022-12-08T06:06:40.358751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.152517</td>\n",
       "      <td>0.944316</td>\n",
       "      <td>0.171470</td>\n",
       "      <td>0.944615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.152190</td>\n",
       "      <td>0.943546</td>\n",
       "      <td>0.167654</td>\n",
       "      <td>0.944615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.150806</td>\n",
       "      <td>0.943546</td>\n",
       "      <td>0.168272</td>\n",
       "      <td>0.944615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.149453</td>\n",
       "      <td>0.944060</td>\n",
       "      <td>0.165566</td>\n",
       "      <td>0.943846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.149114</td>\n",
       "      <td>0.943033</td>\n",
       "      <td>0.166593</td>\n",
       "      <td>0.944615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.993072</td>\n",
       "      <td>0.085554</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.027384</td>\n",
       "      <td>0.991789</td>\n",
       "      <td>0.086801</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.025468</td>\n",
       "      <td>0.992302</td>\n",
       "      <td>0.088677</td>\n",
       "      <td>0.989231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.024388</td>\n",
       "      <td>0.993328</td>\n",
       "      <td>0.086945</td>\n",
       "      <td>0.989231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.024211</td>\n",
       "      <td>0.993072</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>0.988462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss  accuracy  val_loss  val_accuracy\n",
       "0     0.152517  0.944316  0.171470      0.944615\n",
       "1     0.152190  0.943546  0.167654      0.944615\n",
       "2     0.150806  0.943546  0.168272      0.944615\n",
       "3     0.149453  0.944060  0.165566      0.943846\n",
       "4     0.149114  0.943033  0.166593      0.944615\n",
       "...        ...       ...       ...           ...\n",
       "1995  0.025600  0.993072  0.085554      0.990000\n",
       "1996  0.027384  0.991789  0.086801      0.990000\n",
       "1997  0.025468  0.992302  0.088677      0.989231\n",
       "1998  0.024388  0.993328  0.086945      0.989231\n",
       "1999  0.024211  0.993072  0.090244      0.988462\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# history에 저장된 학습 결과를 확인해 보겠습니다. \n",
    "hist_df=pd.DataFrame(history.history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T06:06:40.668434Z",
     "start_time": "2022-12-08T06:06:40.466796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_vloss에 테스트셋(여기서는 검증셋)의 오차를 저장합니다.\n",
    "y_vloss=hist_df['val_loss']\n",
    "\n",
    "# y_loss에 학습셋의 오차를 저장합니다.\n",
    "y_loss=hist_df['loss']\n",
    "\n",
    "# x 값을 지정하고 테스트셋(검증셋)의 오차를 빨간색으로, 학습셋의 오차를 파란색으로 표시합니다.\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2, label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=2, label='Trainset_loss')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 학습의 자동 중단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 코드 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T06:06:40.839018Z",
     "start_time": "2022-12-08T06:06:40.765018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 30)                390       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 12)                372       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 입력합니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "#학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습의 자동 중단 및 최적화 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T06:07:03.629524Z",
     "start_time": "2022-12-08T06:06:40.933676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Ananconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 24ms/step - loss: 18.4429 - accuracy: 0.2425 - val_loss: 11.3774 - val_accuracy: 0.2323\n",
      "Epoch 2/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7.3897 - accuracy: 0.2425 - val_loss: 4.4958 - val_accuracy: 0.2323\n",
      "Epoch 3/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.1515 - accuracy: 0.2425 - val_loss: 1.4369 - val_accuracy: 0.2538\n",
      "Epoch 4/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.8227 - accuracy: 0.5414 - val_loss: 0.4034 - val_accuracy: 0.7823\n",
      "Epoch 5/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3822 - accuracy: 0.7614 - val_loss: 0.3687 - val_accuracy: 0.7685\n",
      "Epoch 6/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.7585 - val_loss: 0.3844 - val_accuracy: 0.7700\n",
      "Epoch 7/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.7624 - val_loss: 0.3762 - val_accuracy: 0.7854\n",
      "Epoch 8/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3834 - accuracy: 0.7803 - val_loss: 0.3526 - val_accuracy: 0.8100\n",
      "Epoch 9/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3537 - accuracy: 0.8109 - val_loss: 0.3209 - val_accuracy: 0.8369\n",
      "Epoch 10/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3195 - accuracy: 0.8396 - val_loss: 0.2963 - val_accuracy: 0.8785\n",
      "Epoch 11/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3003 - accuracy: 0.8732 - val_loss: 0.2900 - val_accuracy: 0.9015\n",
      "Epoch 12/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2958 - accuracy: 0.8976 - val_loss: 0.2860 - val_accuracy: 0.9115\n",
      "Epoch 13/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2884 - accuracy: 0.9007 - val_loss: 0.2768 - val_accuracy: 0.9092\n",
      "Epoch 14/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2803 - accuracy: 0.8974 - val_loss: 0.2691 - val_accuracy: 0.9077\n",
      "Epoch 15/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2730 - accuracy: 0.8979 - val_loss: 0.2615 - val_accuracy: 0.9123\n",
      "Epoch 16/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2648 - accuracy: 0.9025 - val_loss: 0.2526 - val_accuracy: 0.9146\n",
      "Epoch 17/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2554 - accuracy: 0.9117 - val_loss: 0.2438 - val_accuracy: 0.9208\n",
      "Epoch 18/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2450 - accuracy: 0.9163 - val_loss: 0.2338 - val_accuracy: 0.9269\n",
      "Epoch 19/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2319 - accuracy: 0.9246 - val_loss: 0.2247 - val_accuracy: 0.9323\n",
      "Epoch 20/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2226 - accuracy: 0.9307 - val_loss: 0.2185 - val_accuracy: 0.9323\n",
      "Epoch 21/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2165 - accuracy: 0.9310 - val_loss: 0.2124 - val_accuracy: 0.9323\n",
      "Epoch 22/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2128 - accuracy: 0.9299 - val_loss: 0.2087 - val_accuracy: 0.9338\n",
      "Epoch 23/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2102 - accuracy: 0.9317 - val_loss: 0.2054 - val_accuracy: 0.9338\n",
      "Epoch 24/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2075 - accuracy: 0.9333 - val_loss: 0.2027 - val_accuracy: 0.9323\n",
      "Epoch 25/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2050 - accuracy: 0.9335 - val_loss: 0.1998 - val_accuracy: 0.9338\n",
      "Epoch 26/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2031 - accuracy: 0.9343 - val_loss: 0.1983 - val_accuracy: 0.9346\n",
      "Epoch 27/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2004 - accuracy: 0.9348 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 28/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1983 - accuracy: 0.9346 - val_loss: 0.1931 - val_accuracy: 0.9354\n",
      "Epoch 29/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1943 - accuracy: 0.9371 - val_loss: 0.1895 - val_accuracy: 0.9369\n",
      "Epoch 30/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1912 - accuracy: 0.9361 - val_loss: 0.1855 - val_accuracy: 0.9369\n",
      "Epoch 31/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1889 - accuracy: 0.9382 - val_loss: 0.1829 - val_accuracy: 0.9377\n",
      "Epoch 32/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1868 - accuracy: 0.9371 - val_loss: 0.1812 - val_accuracy: 0.9408\n",
      "Epoch 33/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1853 - accuracy: 0.9415 - val_loss: 0.1795 - val_accuracy: 0.9408\n",
      "Epoch 34/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1837 - accuracy: 0.9400 - val_loss: 0.1785 - val_accuracy: 0.9408\n",
      "Epoch 35/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1826 - accuracy: 0.9415 - val_loss: 0.1773 - val_accuracy: 0.9431\n",
      "Epoch 36/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1817 - accuracy: 0.9405 - val_loss: 0.1774 - val_accuracy: 0.9431\n",
      "Epoch 37/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1817 - accuracy: 0.9423 - val_loss: 0.1758 - val_accuracy: 0.9446\n",
      "Epoch 38/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1800 - accuracy: 0.9423 - val_loss: 0.1758 - val_accuracy: 0.9438\n",
      "Epoch 39/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1792 - accuracy: 0.9443 - val_loss: 0.1736 - val_accuracy: 0.9462\n",
      "Epoch 40/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1778 - accuracy: 0.9446 - val_loss: 0.1734 - val_accuracy: 0.9454\n",
      "Epoch 41/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1766 - accuracy: 0.9448 - val_loss: 0.1721 - val_accuracy: 0.9454\n",
      "Epoch 42/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1759 - accuracy: 0.9446 - val_loss: 0.1720 - val_accuracy: 0.9454\n",
      "Epoch 43/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1750 - accuracy: 0.9446 - val_loss: 0.1702 - val_accuracy: 0.9477\n",
      "Epoch 44/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1762 - accuracy: 0.9443 - val_loss: 0.1695 - val_accuracy: 0.9454\n",
      "Epoch 45/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1739 - accuracy: 0.9443 - val_loss: 0.1684 - val_accuracy: 0.9477\n",
      "Epoch 46/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1736 - accuracy: 0.9459 - val_loss: 0.1676 - val_accuracy: 0.9462\n",
      "Epoch 47/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1712 - accuracy: 0.9451 - val_loss: 0.1662 - val_accuracy: 0.9462\n",
      "Epoch 48/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1693 - accuracy: 0.9464 - val_loss: 0.1647 - val_accuracy: 0.9477\n",
      "Epoch 49/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1695 - accuracy: 0.9453 - val_loss: 0.1629 - val_accuracy: 0.9485\n",
      "Epoch 50/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1671 - accuracy: 0.9453 - val_loss: 0.1614 - val_accuracy: 0.9485\n",
      "Epoch 51/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1662 - accuracy: 0.9479 - val_loss: 0.1600 - val_accuracy: 0.9462\n",
      "Epoch 52/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1641 - accuracy: 0.9456 - val_loss: 0.1580 - val_accuracy: 0.9469\n",
      "Epoch 53/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1622 - accuracy: 0.9479 - val_loss: 0.1581 - val_accuracy: 0.9446\n",
      "Epoch 54/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1602 - accuracy: 0.9466 - val_loss: 0.1553 - val_accuracy: 0.9485\n",
      "Epoch 55/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1602 - accuracy: 0.9484 - val_loss: 0.1553 - val_accuracy: 0.9438\n",
      "Epoch 56/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1577 - accuracy: 0.9471 - val_loss: 0.1514 - val_accuracy: 0.9462\n",
      "Epoch 57/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1560 - accuracy: 0.9477 - val_loss: 0.1519 - val_accuracy: 0.9446\n",
      "Epoch 58/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1536 - accuracy: 0.9482 - val_loss: 0.1498 - val_accuracy: 0.9500\n",
      "Epoch 59/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9489 - val_loss: 0.1525 - val_accuracy: 0.9462\n",
      "Epoch 60/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1524 - accuracy: 0.9482 - val_loss: 0.1490 - val_accuracy: 0.9523\n",
      "Epoch 61/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1525 - accuracy: 0.9494 - val_loss: 0.1462 - val_accuracy: 0.9446\n",
      "Epoch 62/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1487 - accuracy: 0.9492 - val_loss: 0.1454 - val_accuracy: 0.9515\n",
      "Epoch 63/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1493 - accuracy: 0.9505 - val_loss: 0.1438 - val_accuracy: 0.9469\n",
      "Epoch 64/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1480 - accuracy: 0.9492 - val_loss: 0.1389 - val_accuracy: 0.9492\n",
      "Epoch 65/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1450 - accuracy: 0.9505 - val_loss: 0.1374 - val_accuracy: 0.9500\n",
      "Epoch 66/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1430 - accuracy: 0.9505 - val_loss: 0.1358 - val_accuracy: 0.9500\n",
      "Epoch 67/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1424 - accuracy: 0.9523 - val_loss: 0.1345 - val_accuracy: 0.9500\n",
      "Epoch 68/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1414 - accuracy: 0.9525 - val_loss: 0.1343 - val_accuracy: 0.9500\n",
      "Epoch 69/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1407 - accuracy: 0.9518 - val_loss: 0.1403 - val_accuracy: 0.9531\n",
      "Epoch 70/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1423 - accuracy: 0.9512 - val_loss: 0.1314 - val_accuracy: 0.9500\n",
      "Epoch 71/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1384 - accuracy: 0.9533 - val_loss: 0.1298 - val_accuracy: 0.9500\n",
      "Epoch 72/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1365 - accuracy: 0.9525 - val_loss: 0.1298 - val_accuracy: 0.9523\n",
      "Epoch 73/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1359 - accuracy: 0.9538 - val_loss: 0.1266 - val_accuracy: 0.9546\n",
      "Epoch 74/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1329 - accuracy: 0.9541 - val_loss: 0.1268 - val_accuracy: 0.9531\n",
      "Epoch 75/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1329 - accuracy: 0.9546 - val_loss: 0.1242 - val_accuracy: 0.9531\n",
      "Epoch 76/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1310 - accuracy: 0.9554 - val_loss: 0.1231 - val_accuracy: 0.9562\n",
      "Epoch 77/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1303 - accuracy: 0.9541 - val_loss: 0.1253 - val_accuracy: 0.9546\n",
      "Epoch 78/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1301 - accuracy: 0.9541 - val_loss: 0.1244 - val_accuracy: 0.9531\n",
      "Epoch 79/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1302 - accuracy: 0.9554 - val_loss: 0.1194 - val_accuracy: 0.9538\n",
      "Epoch 80/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1269 - accuracy: 0.9566 - val_loss: 0.1189 - val_accuracy: 0.9562\n",
      "Epoch 81/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1259 - accuracy: 0.9569 - val_loss: 0.1176 - val_accuracy: 0.9554\n",
      "Epoch 82/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1249 - accuracy: 0.9579 - val_loss: 0.1164 - val_accuracy: 0.9554\n",
      "Epoch 83/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1239 - accuracy: 0.9584 - val_loss: 0.1153 - val_accuracy: 0.9554\n",
      "Epoch 84/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1229 - accuracy: 0.9566 - val_loss: 0.1153 - val_accuracy: 0.9569\n",
      "Epoch 85/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1225 - accuracy: 0.9589 - val_loss: 0.1136 - val_accuracy: 0.9554\n",
      "Epoch 86/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1202 - accuracy: 0.9589 - val_loss: 0.1147 - val_accuracy: 0.9615\n",
      "Epoch 87/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1199 - accuracy: 0.9592 - val_loss: 0.1113 - val_accuracy: 0.9577\n",
      "Epoch 88/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1204 - accuracy: 0.9602 - val_loss: 0.1102 - val_accuracy: 0.9600\n",
      "Epoch 89/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1195 - accuracy: 0.9592 - val_loss: 0.1097 - val_accuracy: 0.9592\n",
      "Epoch 90/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1172 - accuracy: 0.9597 - val_loss: 0.1085 - val_accuracy: 0.9600\n",
      "Epoch 91/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1165 - accuracy: 0.9605 - val_loss: 0.1078 - val_accuracy: 0.9600\n",
      "Epoch 92/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1158 - accuracy: 0.9613 - val_loss: 0.1072 - val_accuracy: 0.9592\n",
      "Epoch 93/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1157 - accuracy: 0.9607 - val_loss: 0.1071 - val_accuracy: 0.9577\n",
      "Epoch 94/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1146 - accuracy: 0.9620 - val_loss: 0.1048 - val_accuracy: 0.9623\n",
      "Epoch 95/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1132 - accuracy: 0.9628 - val_loss: 0.1064 - val_accuracy: 0.9654\n",
      "Epoch 96/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1130 - accuracy: 0.9630 - val_loss: 0.1045 - val_accuracy: 0.9585\n",
      "Epoch 97/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1120 - accuracy: 0.9636 - val_loss: 0.1021 - val_accuracy: 0.9623\n",
      "Epoch 98/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9610 - val_loss: 0.1029 - val_accuracy: 0.9654\n",
      "Epoch 99/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1103 - accuracy: 0.9633 - val_loss: 0.1009 - val_accuracy: 0.9646\n",
      "Epoch 100/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1089 - accuracy: 0.9648 - val_loss: 0.1001 - val_accuracy: 0.9623\n",
      "Epoch 101/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1092 - accuracy: 0.9625 - val_loss: 0.0995 - val_accuracy: 0.9662\n",
      "Epoch 102/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1067 - accuracy: 0.9643 - val_loss: 0.0970 - val_accuracy: 0.9646\n",
      "Epoch 103/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1055 - accuracy: 0.9666 - val_loss: 0.0960 - val_accuracy: 0.9662\n",
      "Epoch 104/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1050 - accuracy: 0.9666 - val_loss: 0.0949 - val_accuracy: 0.9631\n",
      "Epoch 105/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1051 - accuracy: 0.9659 - val_loss: 0.0950 - val_accuracy: 0.9646\n",
      "Epoch 106/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.9669 - val_loss: 0.0971 - val_accuracy: 0.9677\n",
      "Epoch 107/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1037 - accuracy: 0.9666 - val_loss: 0.0924 - val_accuracy: 0.9685\n",
      "Epoch 108/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9690 - val_loss: 0.0933 - val_accuracy: 0.9654\n",
      "Epoch 109/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1009 - accuracy: 0.9695 - val_loss: 0.0918 - val_accuracy: 0.9692\n",
      "Epoch 110/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0998 - accuracy: 0.9687 - val_loss: 0.0899 - val_accuracy: 0.9677\n",
      "Epoch 111/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1002 - accuracy: 0.9684 - val_loss: 0.0920 - val_accuracy: 0.9654\n",
      "Epoch 112/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0995 - accuracy: 0.9672 - val_loss: 0.0888 - val_accuracy: 0.9677\n",
      "Epoch 113/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0972 - accuracy: 0.9687 - val_loss: 0.0878 - val_accuracy: 0.9692\n",
      "Epoch 114/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9695 - val_loss: 0.0880 - val_accuracy: 0.9715\n",
      "Epoch 115/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0962 - accuracy: 0.9697 - val_loss: 0.0872 - val_accuracy: 0.9715\n",
      "Epoch 116/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9705 - val_loss: 0.0875 - val_accuracy: 0.9669\n",
      "Epoch 117/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9720 - val_loss: 0.0879 - val_accuracy: 0.9662\n",
      "Epoch 118/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0948 - accuracy: 0.9700 - val_loss: 0.0921 - val_accuracy: 0.9731\n",
      "Epoch 119/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0963 - accuracy: 0.9695 - val_loss: 0.0844 - val_accuracy: 0.9692\n",
      "Epoch 120/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9695 - val_loss: 0.1015 - val_accuracy: 0.9615\n",
      "Epoch 121/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9666 - val_loss: 0.0870 - val_accuracy: 0.9746\n",
      "Epoch 122/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0922 - accuracy: 0.9710 - val_loss: 0.0834 - val_accuracy: 0.9715\n",
      "Epoch 123/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0907 - accuracy: 0.9715 - val_loss: 0.0828 - val_accuracy: 0.9723\n",
      "Epoch 124/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0900 - accuracy: 0.9728 - val_loss: 0.0870 - val_accuracy: 0.9762\n",
      "Epoch 125/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0939 - accuracy: 0.9713 - val_loss: 0.0827 - val_accuracy: 0.9723\n",
      "Epoch 126/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0897 - accuracy: 0.9746 - val_loss: 0.0843 - val_accuracy: 0.9692\n",
      "Epoch 127/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0898 - accuracy: 0.9725 - val_loss: 0.0851 - val_accuracy: 0.9738\n",
      "Epoch 128/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0883 - accuracy: 0.9723 - val_loss: 0.0815 - val_accuracy: 0.9746\n",
      "Epoch 129/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0879 - accuracy: 0.9728 - val_loss: 0.0812 - val_accuracy: 0.9715\n",
      "Epoch 130/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0871 - accuracy: 0.9749 - val_loss: 0.0798 - val_accuracy: 0.9762\n",
      "Epoch 131/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0866 - accuracy: 0.9751 - val_loss: 0.0800 - val_accuracy: 0.9738\n",
      "Epoch 132/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 0.9756 - val_loss: 0.0810 - val_accuracy: 0.9708\n",
      "Epoch 133/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0862 - accuracy: 0.9746 - val_loss: 0.0787 - val_accuracy: 0.9762\n",
      "Epoch 134/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0846 - accuracy: 0.9749 - val_loss: 0.0781 - val_accuracy: 0.9762\n",
      "Epoch 135/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0842 - accuracy: 0.9754 - val_loss: 0.0786 - val_accuracy: 0.9723\n",
      "Epoch 136/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0872 - accuracy: 0.9741 - val_loss: 0.0766 - val_accuracy: 0.9762\n",
      "Epoch 137/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9728 - val_loss: 0.0807 - val_accuracy: 0.9762\n",
      "Epoch 138/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0859 - accuracy: 0.9751 - val_loss: 0.0758 - val_accuracy: 0.9762\n",
      "Epoch 139/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0833 - accuracy: 0.9759 - val_loss: 0.0762 - val_accuracy: 0.9715\n",
      "Epoch 140/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9772 - val_loss: 0.0745 - val_accuracy: 0.9762\n",
      "Epoch 141/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0816 - accuracy: 0.9754 - val_loss: 0.0742 - val_accuracy: 0.9762\n",
      "Epoch 142/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0807 - accuracy: 0.9766 - val_loss: 0.0734 - val_accuracy: 0.9769\n",
      "Epoch 143/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0801 - accuracy: 0.9764 - val_loss: 0.0729 - val_accuracy: 0.9762\n",
      "Epoch 144/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0802 - accuracy: 0.9764 - val_loss: 0.0740 - val_accuracy: 0.9715\n",
      "Epoch 145/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0802 - accuracy: 0.9754 - val_loss: 0.0728 - val_accuracy: 0.9769\n",
      "Epoch 146/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0787 - accuracy: 0.9772 - val_loss: 0.0715 - val_accuracy: 0.9777\n",
      "Epoch 147/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0795 - accuracy: 0.9766 - val_loss: 0.0713 - val_accuracy: 0.9762\n",
      "Epoch 148/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9741 - val_loss: 0.0723 - val_accuracy: 0.9715\n",
      "Epoch 149/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0777 - accuracy: 0.9774 - val_loss: 0.0701 - val_accuracy: 0.9777\n",
      "Epoch 150/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9774 - val_loss: 0.0707 - val_accuracy: 0.9792\n",
      "Epoch 151/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0766 - accuracy: 0.9766 - val_loss: 0.0698 - val_accuracy: 0.9785\n",
      "Epoch 152/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0759 - accuracy: 0.9779 - val_loss: 0.0692 - val_accuracy: 0.9769\n",
      "Epoch 153/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0760 - accuracy: 0.9772 - val_loss: 0.0691 - val_accuracy: 0.9777\n",
      "Epoch 154/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0760 - accuracy: 0.9772 - val_loss: 0.0795 - val_accuracy: 0.9777\n",
      "Epoch 155/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9754 - val_loss: 0.0693 - val_accuracy: 0.9808\n",
      "Epoch 156/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0767 - accuracy: 0.9772 - val_loss: 0.0683 - val_accuracy: 0.9769\n",
      "Epoch 157/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9756 - val_loss: 0.0689 - val_accuracy: 0.9762\n",
      "Epoch 158/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0752 - accuracy: 0.9777 - val_loss: 0.0773 - val_accuracy: 0.9708\n",
      "Epoch 159/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0799 - accuracy: 0.9736 - val_loss: 0.0677 - val_accuracy: 0.9785\n",
      "Epoch 160/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9774 - val_loss: 0.0684 - val_accuracy: 0.9792\n",
      "Epoch 161/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.0675 - val_accuracy: 0.9800\n",
      "Epoch 162/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0721 - accuracy: 0.9797 - val_loss: 0.0670 - val_accuracy: 0.9792\n",
      "Epoch 163/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0720 - accuracy: 0.9795 - val_loss: 0.0668 - val_accuracy: 0.9785\n",
      "Epoch 164/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0716 - accuracy: 0.9795 - val_loss: 0.0663 - val_accuracy: 0.9800\n",
      "Epoch 165/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9792 - val_loss: 0.0671 - val_accuracy: 0.9792\n",
      "Epoch 166/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9787 - val_loss: 0.0674 - val_accuracy: 0.9769\n",
      "Epoch 167/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9792 - val_loss: 0.0663 - val_accuracy: 0.9808\n",
      "Epoch 168/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9790 - val_loss: 0.0683 - val_accuracy: 0.9746\n",
      "Epoch 169/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0714 - accuracy: 0.9802 - val_loss: 0.0654 - val_accuracy: 0.9800\n",
      "Epoch 170/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.9792 - val_loss: 0.0690 - val_accuracy: 0.9785\n",
      "Epoch 171/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9784 - val_loss: 0.0667 - val_accuracy: 0.9808\n",
      "Epoch 172/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0691 - accuracy: 0.9805 - val_loss: 0.0652 - val_accuracy: 0.9800\n",
      "Epoch 173/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.9808 - val_loss: 0.0668 - val_accuracy: 0.9800\n",
      "Epoch 174/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9797 - val_loss: 0.0658 - val_accuracy: 0.9815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9815 - val_loss: 0.0647 - val_accuracy: 0.9800\n",
      "Epoch 176/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9782 - val_loss: 0.0684 - val_accuracy: 0.9746\n",
      "Epoch 177/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.9795 - val_loss: 0.0702 - val_accuracy: 0.9738\n",
      "Epoch 178/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9790 - val_loss: 0.0658 - val_accuracy: 0.9808\n",
      "Epoch 179/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0678 - accuracy: 0.9797 - val_loss: 0.0639 - val_accuracy: 0.9808\n",
      "Epoch 180/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9797 - val_loss: 0.0672 - val_accuracy: 0.9800\n",
      "Epoch 181/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.9800 - val_loss: 0.0640 - val_accuracy: 0.9815\n",
      "Epoch 182/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0675 - accuracy: 0.9805 - val_loss: 0.0634 - val_accuracy: 0.9823\n",
      "Epoch 183/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0669 - accuracy: 0.9795 - val_loss: 0.0630 - val_accuracy: 0.9815\n",
      "Epoch 184/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9805 - val_loss: 0.0657 - val_accuracy: 0.9800\n",
      "Epoch 185/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9802 - val_loss: 0.0644 - val_accuracy: 0.9785\n",
      "Epoch 186/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0661 - accuracy: 0.9808 - val_loss: 0.0625 - val_accuracy: 0.9823\n",
      "Epoch 187/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.9792 - val_loss: 0.0628 - val_accuracy: 0.9823\n",
      "Epoch 188/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9800 - val_loss: 0.0646 - val_accuracy: 0.9815\n",
      "Epoch 189/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0664 - accuracy: 0.9802 - val_loss: 0.0620 - val_accuracy: 0.9823\n",
      "Epoch 190/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.9800 - val_loss: 0.0624 - val_accuracy: 0.9800\n",
      "Epoch 191/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0663 - accuracy: 0.9797 - val_loss: 0.0620 - val_accuracy: 0.9800\n",
      "Epoch 192/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9805 - val_loss: 0.0625 - val_accuracy: 0.9800\n",
      "Epoch 193/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0652 - accuracy: 0.9808 - val_loss: 0.0614 - val_accuracy: 0.9823\n",
      "Epoch 194/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0635 - accuracy: 0.9810 - val_loss: 0.0610 - val_accuracy: 0.9815\n",
      "Epoch 195/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.9810 - val_loss: 0.0614 - val_accuracy: 0.9823\n",
      "Epoch 196/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9818 - val_loss: 0.0649 - val_accuracy: 0.9754\n",
      "Epoch 197/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0684 - accuracy: 0.9797 - val_loss: 0.0608 - val_accuracy: 0.9823\n",
      "Epoch 198/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9802 - val_loss: 0.0638 - val_accuracy: 0.9823\n",
      "Epoch 199/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9808 - val_loss: 0.0659 - val_accuracy: 0.9823\n",
      "Epoch 200/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9808 - val_loss: 0.0615 - val_accuracy: 0.9823\n",
      "Epoch 201/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0630 - accuracy: 0.9818 - val_loss: 0.0601 - val_accuracy: 0.9831\n",
      "Epoch 202/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.9813 - val_loss: 0.0619 - val_accuracy: 0.9831\n",
      "Epoch 203/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0624 - accuracy: 0.9810 - val_loss: 0.0596 - val_accuracy: 0.9838\n",
      "Epoch 204/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.9810 - val_loss: 0.0600 - val_accuracy: 0.9823\n",
      "Epoch 205/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.9818 - val_loss: 0.0607 - val_accuracy: 0.9823\n",
      "Epoch 206/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9808 - val_loss: 0.0600 - val_accuracy: 0.9823\n",
      "Epoch 207/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0625 - accuracy: 0.9820 - val_loss: 0.0599 - val_accuracy: 0.9808\n",
      "Epoch 208/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.9818 - val_loss: 0.0606 - val_accuracy: 0.9815\n",
      "Epoch 209/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0653 - accuracy: 0.9813 - val_loss: 0.0595 - val_accuracy: 0.9823\n",
      "Epoch 210/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0625 - accuracy: 0.9820 - val_loss: 0.0640 - val_accuracy: 0.9754\n",
      "Epoch 211/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0640 - accuracy: 0.9805 - val_loss: 0.0586 - val_accuracy: 0.9831\n",
      "Epoch 212/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0608 - accuracy: 0.9823 - val_loss: 0.0586 - val_accuracy: 0.9846\n",
      "Epoch 213/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.9820 - val_loss: 0.0590 - val_accuracy: 0.9823\n",
      "Epoch 214/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0609 - accuracy: 0.9820 - val_loss: 0.0584 - val_accuracy: 0.9838\n",
      "Epoch 215/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9820 - val_loss: 0.0586 - val_accuracy: 0.9823\n",
      "Epoch 216/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9820 - val_loss: 0.0590 - val_accuracy: 0.9823\n",
      "Epoch 217/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9826 - val_loss: 0.0586 - val_accuracy: 0.9823\n",
      "Epoch 218/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0594 - accuracy: 0.9828 - val_loss: 0.0615 - val_accuracy: 0.9838\n",
      "Epoch 219/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0601 - accuracy: 0.9823 - val_loss: 0.0573 - val_accuracy: 0.9838\n",
      "Epoch 220/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.9820 - val_loss: 0.0616 - val_accuracy: 0.9838\n",
      "Epoch 221/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9820 - val_loss: 0.0647 - val_accuracy: 0.9823\n",
      "Epoch 222/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9813 - val_loss: 0.0649 - val_accuracy: 0.9808\n",
      "Epoch 223/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.9813 - val_loss: 0.0570 - val_accuracy: 0.9838\n",
      "Epoch 224/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9838 - val_loss: 0.0634 - val_accuracy: 0.9746\n",
      "Epoch 225/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.9818 - val_loss: 0.0606 - val_accuracy: 0.9769\n",
      "Epoch 226/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9779 - val_loss: 0.0620 - val_accuracy: 0.9762\n",
      "Epoch 227/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9813 - val_loss: 0.0574 - val_accuracy: 0.9823\n",
      "Epoch 228/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0597 - accuracy: 0.9810 - val_loss: 0.0566 - val_accuracy: 0.9831\n",
      "Epoch 229/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0590 - accuracy: 0.9828 - val_loss: 0.0559 - val_accuracy: 0.9838\n",
      "Epoch 230/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9836 - val_loss: 0.0566 - val_accuracy: 0.9823\n",
      "Epoch 231/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9846 - val_loss: 0.0563 - val_accuracy: 0.9838\n",
      "Epoch 232/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9836 - val_loss: 0.0562 - val_accuracy: 0.9831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9843 - val_loss: 0.0582 - val_accuracy: 0.9838\n",
      "Epoch 234/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0592 - accuracy: 0.9836 - val_loss: 0.0553 - val_accuracy: 0.9838\n",
      "Epoch 235/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9851 - val_loss: 0.0559 - val_accuracy: 0.9831\n",
      "Epoch 236/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9828 - val_loss: 0.0634 - val_accuracy: 0.9823\n",
      "Epoch 237/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.9800 - val_loss: 0.0616 - val_accuracy: 0.9831\n",
      "Epoch 238/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9833 - val_loss: 0.0564 - val_accuracy: 0.9823\n",
      "Epoch 239/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9841 - val_loss: 0.0561 - val_accuracy: 0.9831\n",
      "Epoch 240/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9846 - val_loss: 0.0580 - val_accuracy: 0.9846\n",
      "Epoch 241/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9831 - val_loss: 0.0577 - val_accuracy: 0.9838\n",
      "Epoch 242/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9836 - val_loss: 0.0578 - val_accuracy: 0.9846\n",
      "Epoch 243/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0575 - accuracy: 0.9838 - val_loss: 0.0545 - val_accuracy: 0.9838\n",
      "Epoch 244/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0578 - accuracy: 0.9831 - val_loss: 0.0543 - val_accuracy: 0.9838\n",
      "Epoch 245/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9846 - val_loss: 0.0547 - val_accuracy: 0.9831\n",
      "Epoch 246/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9838 - val_loss: 0.0563 - val_accuracy: 0.9800\n",
      "Epoch 247/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9820 - val_loss: 0.0564 - val_accuracy: 0.9800\n",
      "Epoch 248/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9815 - val_loss: 0.0562 - val_accuracy: 0.9808\n",
      "Epoch 249/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9831 - val_loss: 0.0554 - val_accuracy: 0.9838\n",
      "Epoch 250/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9826 - val_loss: 0.0638 - val_accuracy: 0.9792\n",
      "Epoch 251/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9833 - val_loss: 0.0586 - val_accuracy: 0.9815\n",
      "Epoch 252/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9854 - val_loss: 0.0573 - val_accuracy: 0.9838\n",
      "Epoch 253/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0560 - accuracy: 0.9849 - val_loss: 0.0537 - val_accuracy: 0.9838\n",
      "Epoch 254/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9838 - val_loss: 0.0634 - val_accuracy: 0.9815\n",
      "Epoch 255/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9826 - val_loss: 0.0713 - val_accuracy: 0.9785\n",
      "Epoch 256/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9823 - val_loss: 0.0569 - val_accuracy: 0.9823\n",
      "Epoch 257/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9843 - val_loss: 0.0543 - val_accuracy: 0.9846\n",
      "Epoch 258/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0555 - accuracy: 0.9838 - val_loss: 0.0532 - val_accuracy: 0.9846\n",
      "Epoch 259/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0563 - accuracy: 0.9851 - val_loss: 0.0528 - val_accuracy: 0.9838\n",
      "Epoch 260/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9833 - val_loss: 0.0530 - val_accuracy: 0.9838\n",
      "Epoch 261/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.9849 - val_loss: 0.0542 - val_accuracy: 0.9838\n",
      "Epoch 262/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9843 - val_loss: 0.0578 - val_accuracy: 0.9831\n",
      "Epoch 263/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9838 - val_loss: 0.0562 - val_accuracy: 0.9831\n",
      "Epoch 264/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9843 - val_loss: 0.0590 - val_accuracy: 0.9823\n",
      "Epoch 265/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9846 - val_loss: 0.0536 - val_accuracy: 0.9838\n",
      "Epoch 266/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9841 - val_loss: 0.0534 - val_accuracy: 0.9846\n",
      "Epoch 267/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0543 - accuracy: 0.9854 - val_loss: 0.0524 - val_accuracy: 0.9846\n",
      "Epoch 268/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9846 - val_loss: 0.0545 - val_accuracy: 0.9831\n",
      "Epoch 269/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0557 - accuracy: 0.9828 - val_loss: 0.0703 - val_accuracy: 0.9785\n",
      "Epoch 270/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9808 - val_loss: 0.0597 - val_accuracy: 0.9815\n",
      "Epoch 271/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9828 - val_loss: 0.0539 - val_accuracy: 0.9815\n",
      "Epoch 272/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0552 - accuracy: 0.9828 - val_loss: 0.0521 - val_accuracy: 0.9846\n",
      "Epoch 273/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9851 - val_loss: 0.0532 - val_accuracy: 0.9831\n",
      "Epoch 274/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0535 - accuracy: 0.9843 - val_loss: 0.0518 - val_accuracy: 0.9846\n",
      "Epoch 275/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9849 - val_loss: 0.0525 - val_accuracy: 0.9846\n",
      "Epoch 276/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0538 - accuracy: 0.9846 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
      "Epoch 277/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0548 - accuracy: 0.9846 - val_loss: 0.0515 - val_accuracy: 0.9838\n",
      "Epoch 278/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9851 - val_loss: 0.0520 - val_accuracy: 0.9846\n",
      "Epoch 279/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9836 - val_loss: 0.0541 - val_accuracy: 0.9815\n",
      "Epoch 280/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9846 - val_loss: 0.0518 - val_accuracy: 0.9846\n",
      "Epoch 281/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9849 - val_loss: 0.0518 - val_accuracy: 0.9846\n",
      "Epoch 282/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0552 - accuracy: 0.9846 - val_loss: 0.0511 - val_accuracy: 0.9846\n",
      "Epoch 283/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9843 - val_loss: 0.0538 - val_accuracy: 0.9815\n",
      "Epoch 284/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9846 - val_loss: 0.0518 - val_accuracy: 0.9854\n",
      "Epoch 285/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0530 - accuracy: 0.9846 - val_loss: 0.0508 - val_accuracy: 0.9846\n",
      "Epoch 286/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0524 - accuracy: 0.9841 - val_loss: 0.0506 - val_accuracy: 0.9846\n",
      "Epoch 287/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9843 - val_loss: 0.0523 - val_accuracy: 0.9846\n",
      "Epoch 288/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9854 - val_loss: 0.0518 - val_accuracy: 0.9854\n",
      "Epoch 289/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9851 - val_loss: 0.0541 - val_accuracy: 0.9846\n",
      "Epoch 290/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9843 - val_loss: 0.0507 - val_accuracy: 0.9838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9854 - val_loss: 0.0539 - val_accuracy: 0.9815\n",
      "Epoch 292/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0552 - accuracy: 0.9838 - val_loss: 0.0503 - val_accuracy: 0.9846\n",
      "Epoch 293/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9856 - val_loss: 0.0559 - val_accuracy: 0.9777\n",
      "Epoch 294/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.9846 - val_loss: 0.0504 - val_accuracy: 0.9846\n",
      "Epoch 295/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.9846 - val_loss: 0.0512 - val_accuracy: 0.9838\n",
      "Epoch 296/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0522 - accuracy: 0.9849 - val_loss: 0.0502 - val_accuracy: 0.9846\n",
      "Epoch 297/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9851 - val_loss: 0.0515 - val_accuracy: 0.9846\n",
      "Epoch 298/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9859 - val_loss: 0.0520 - val_accuracy: 0.9838\n",
      "Epoch 299/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.9836 - val_loss: 0.0529 - val_accuracy: 0.9846\n",
      "Epoch 300/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9851 - val_loss: 0.0502 - val_accuracy: 0.9846\n",
      "Epoch 301/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0544 - accuracy: 0.9826 - val_loss: 0.0503 - val_accuracy: 0.9846\n",
      "Epoch 302/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9856 - val_loss: 0.0509 - val_accuracy: 0.9846\n",
      "Epoch 303/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9849 - val_loss: 0.0518 - val_accuracy: 0.9838\n",
      "Epoch 304/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0548 - accuracy: 0.9831 - val_loss: 0.0497 - val_accuracy: 0.9846\n",
      "Epoch 305/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9849 - val_loss: 0.0511 - val_accuracy: 0.9846\n",
      "Epoch 306/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9836 - val_loss: 0.0506 - val_accuracy: 0.9846\n",
      "Epoch 307/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0519 - accuracy: 0.9851 - val_loss: 0.0494 - val_accuracy: 0.9846\n",
      "Epoch 308/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.9859 - val_loss: 0.0501 - val_accuracy: 0.9846\n",
      "Epoch 309/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0510 - accuracy: 0.9849 - val_loss: 0.0491 - val_accuracy: 0.9846\n",
      "Epoch 310/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9854 - val_loss: 0.0517 - val_accuracy: 0.9831\n",
      "Epoch 311/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9851 - val_loss: 0.0536 - val_accuracy: 0.9815\n",
      "Epoch 312/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9838 - val_loss: 0.0503 - val_accuracy: 0.9846\n",
      "Epoch 313/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9856 - val_loss: 0.0509 - val_accuracy: 0.9846\n",
      "Epoch 314/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9831 - val_loss: 0.0561 - val_accuracy: 0.9769\n",
      "Epoch 315/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 0.9826 - val_loss: 0.0549 - val_accuracy: 0.9792\n",
      "Epoch 316/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.9843 - val_loss: 0.0550 - val_accuracy: 0.9792\n",
      "Epoch 317/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9843 - val_loss: 0.0521 - val_accuracy: 0.9815\n",
      "Epoch 318/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9838 - val_loss: 0.0605 - val_accuracy: 0.9769\n",
      "Epoch 319/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0542 - accuracy: 0.9849 - val_loss: 0.0502 - val_accuracy: 0.9846\n",
      "Epoch 320/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9849 - val_loss: 0.0503 - val_accuracy: 0.9846\n",
      "Epoch 321/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0501 - accuracy: 0.9851 - val_loss: 0.0490 - val_accuracy: 0.9846\n",
      "Epoch 322/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9859 - val_loss: 0.0558 - val_accuracy: 0.9838\n",
      "Epoch 323/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9859 - val_loss: 0.0587 - val_accuracy: 0.9792\n",
      "Epoch 324/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9849 - val_loss: 0.0550 - val_accuracy: 0.9831\n",
      "Epoch 325/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.9851 - val_loss: 0.0581 - val_accuracy: 0.9800\n",
      "Epoch 326/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9833 - val_loss: 0.0737 - val_accuracy: 0.9777\n",
      "Epoch 327/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9818 - val_loss: 0.0785 - val_accuracy: 0.9746\n",
      "Epoch 328/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0596 - accuracy: 0.9831 - val_loss: 0.0608 - val_accuracy: 0.9800\n",
      "Epoch 329/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9828 - val_loss: 0.0515 - val_accuracy: 0.9838\n",
      "Epoch 330/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0530 - accuracy: 0.9861 - val_loss: 0.0483 - val_accuracy: 0.9846\n",
      "Epoch 331/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9846 - val_loss: 0.0511 - val_accuracy: 0.9823\n",
      "Epoch 332/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9831 - val_loss: 0.0623 - val_accuracy: 0.9762\n",
      "Epoch 333/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.9831 - val_loss: 0.0615 - val_accuracy: 0.9769\n",
      "Epoch 334/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.9820 - val_loss: 0.0489 - val_accuracy: 0.9846\n",
      "Epoch 335/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0516 - accuracy: 0.9843 - val_loss: 0.0480 - val_accuracy: 0.9846\n",
      "Epoch 336/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9838 - val_loss: 0.0491 - val_accuracy: 0.9846\n",
      "Epoch 337/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9836 - val_loss: 0.0504 - val_accuracy: 0.9838\n",
      "Epoch 338/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0497 - accuracy: 0.9867 - val_loss: 0.0480 - val_accuracy: 0.9846\n",
      "Epoch 339/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9856 - val_loss: 0.0499 - val_accuracy: 0.9838\n",
      "Epoch 340/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.0489 - val_accuracy: 0.9846\n",
      "Epoch 341/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9864 - val_loss: 0.0484 - val_accuracy: 0.9838\n",
      "Epoch 342/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9854 - val_loss: 0.0520 - val_accuracy: 0.9838\n",
      "Epoch 343/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9851 - val_loss: 0.0660 - val_accuracy: 0.9800\n",
      "Epoch 344/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9846 - val_loss: 0.0488 - val_accuracy: 0.9838\n",
      "Epoch 345/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9859 - val_loss: 0.0487 - val_accuracy: 0.9838\n",
      "Epoch 346/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0492 - accuracy: 0.9856 - val_loss: 0.0480 - val_accuracy: 0.9846\n",
      "Epoch 347/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.9856 - val_loss: 0.0499 - val_accuracy: 0.9831\n",
      "Epoch 348/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9856 - val_loss: 0.0529 - val_accuracy: 0.9815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.9849 - val_loss: 0.0496 - val_accuracy: 0.9854\n",
      "Epoch 350/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9861 - val_loss: 0.0481 - val_accuracy: 0.9854\n",
      "Epoch 351/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9872 - val_loss: 0.0561 - val_accuracy: 0.9823\n",
      "Epoch 352/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9851 - val_loss: 0.0520 - val_accuracy: 0.9823\n",
      "Epoch 353/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 0.9841 - val_loss: 0.0495 - val_accuracy: 0.9831\n",
      "Epoch 354/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9859 - val_loss: 0.0482 - val_accuracy: 0.9846\n",
      "Epoch 355/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9849 - val_loss: 0.0476 - val_accuracy: 0.9846\n",
      "Epoch 356/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0480 - accuracy: 0.9854 - val_loss: 0.0488 - val_accuracy: 0.9854\n",
      "Epoch 357/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0486 - accuracy: 0.9851 - val_loss: 0.0502 - val_accuracy: 0.9846\n",
      "Epoch 358/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9838 - val_loss: 0.0477 - val_accuracy: 0.9846\n",
      "Epoch 359/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0542 - accuracy: 0.9843 - val_loss: 0.0475 - val_accuracy: 0.9846\n",
      "Epoch 360/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9856 - val_loss: 0.0555 - val_accuracy: 0.9823\n",
      "Epoch 361/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9859 - val_loss: 0.0497 - val_accuracy: 0.9823\n",
      "Epoch 362/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9867 - val_loss: 0.0513 - val_accuracy: 0.9831\n",
      "Epoch 363/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9867 - val_loss: 0.0588 - val_accuracy: 0.9815\n",
      "Epoch 364/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9854 - val_loss: 0.0515 - val_accuracy: 0.9854\n",
      "Epoch 365/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 0.9861 - val_loss: 0.0469 - val_accuracy: 0.9854\n",
      "Epoch 366/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0471 - accuracy: 0.9864 - val_loss: 0.0494 - val_accuracy: 0.9854\n",
      "Epoch 367/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9851 - val_loss: 0.0483 - val_accuracy: 0.9838\n",
      "Epoch 368/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9849 - val_loss: 0.0517 - val_accuracy: 0.9846\n",
      "Epoch 369/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9854 - val_loss: 0.0516 - val_accuracy: 0.9862\n",
      "Epoch 370/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9867 - val_loss: 0.0527 - val_accuracy: 0.9838\n",
      "Epoch 371/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.9861 - val_loss: 0.0495 - val_accuracy: 0.9831\n",
      "Epoch 372/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0475 - accuracy: 0.9859 - val_loss: 0.0464 - val_accuracy: 0.9854\n",
      "Epoch 373/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0484 - accuracy: 0.9859 - val_loss: 0.0486 - val_accuracy: 0.9862\n",
      "Epoch 374/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9869 - val_loss: 0.0495 - val_accuracy: 0.9838\n",
      "Epoch 375/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9867 - val_loss: 0.0481 - val_accuracy: 0.9838\n",
      "Epoch 376/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9859 - val_loss: 0.0484 - val_accuracy: 0.9854\n",
      "Epoch 377/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 0.9867 - val_loss: 0.0468 - val_accuracy: 0.9862\n",
      "Epoch 378/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0463 - accuracy: 0.9856 - val_loss: 0.0509 - val_accuracy: 0.9838\n",
      "Epoch 379/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0475 - accuracy: 0.9856 - val_loss: 0.0460 - val_accuracy: 0.9854\n",
      "Epoch 380/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0481 - accuracy: 0.9872 - val_loss: 0.0472 - val_accuracy: 0.9862\n",
      "Epoch 381/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9867 - val_loss: 0.0571 - val_accuracy: 0.9815\n",
      "Epoch 382/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9851 - val_loss: 0.0702 - val_accuracy: 0.9754\n",
      "Epoch 383/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.9843 - val_loss: 0.0620 - val_accuracy: 0.9808\n",
      "Epoch 384/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9867 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
      "Epoch 385/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9864 - val_loss: 0.0498 - val_accuracy: 0.9862\n",
      "Epoch 386/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9851 - val_loss: 0.0475 - val_accuracy: 0.9846\n",
      "Epoch 387/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.9864 - val_loss: 0.0486 - val_accuracy: 0.9854\n",
      "Epoch 388/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9872 - val_loss: 0.0472 - val_accuracy: 0.9854\n",
      "Epoch 389/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0486 - accuracy: 0.9869 - val_loss: 0.0460 - val_accuracy: 0.9862\n",
      "Epoch 390/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9854 - val_loss: 0.0471 - val_accuracy: 0.9838\n",
      "Epoch 391/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0544 - accuracy: 0.9849 - val_loss: 0.0467 - val_accuracy: 0.9854\n",
      "Epoch 392/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9854 - val_loss: 0.0462 - val_accuracy: 0.9862\n",
      "Epoch 393/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0497 - accuracy: 0.9877 - val_loss: 0.0454 - val_accuracy: 0.9862\n",
      "Epoch 394/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9846 - val_loss: 0.0468 - val_accuracy: 0.9838\n",
      "Epoch 395/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9836 - val_loss: 0.0550 - val_accuracy: 0.9823\n",
      "Epoch 396/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0569 - accuracy: 0.9826 - val_loss: 0.0611 - val_accuracy: 0.9777\n",
      "Epoch 397/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9846 - val_loss: 0.0514 - val_accuracy: 0.9838\n",
      "Epoch 398/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0477 - accuracy: 0.9856 - val_loss: 0.0458 - val_accuracy: 0.9862\n",
      "Epoch 399/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0487 - accuracy: 0.9854 - val_loss: 0.0451 - val_accuracy: 0.9862\n",
      "Epoch 400/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0486 - accuracy: 0.9859 - val_loss: 0.0472 - val_accuracy: 0.9862\n",
      "Epoch 401/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.9867 - val_loss: 0.0466 - val_accuracy: 0.9862\n",
      "Epoch 402/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9861 - val_loss: 0.0452 - val_accuracy: 0.9862\n",
      "Epoch 403/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9846 - val_loss: 0.0460 - val_accuracy: 0.9862\n",
      "Epoch 404/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0454 - accuracy: 0.9869 - val_loss: 0.0472 - val_accuracy: 0.9862\n",
      "Epoch 405/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9869 - val_loss: 0.0461 - val_accuracy: 0.9862\n",
      "Epoch 406/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0477 - accuracy: 0.9861 - val_loss: 0.0473 - val_accuracy: 0.9862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9859 - val_loss: 0.0455 - val_accuracy: 0.9846\n",
      "Epoch 408/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9872 - val_loss: 0.0444 - val_accuracy: 0.9854\n",
      "Epoch 409/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9861 - val_loss: 0.0552 - val_accuracy: 0.9815\n",
      "Epoch 410/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9843 - val_loss: 0.0464 - val_accuracy: 0.9854\n",
      "Epoch 411/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9867 - val_loss: 0.0575 - val_accuracy: 0.9777\n",
      "Epoch 412/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9836 - val_loss: 0.0523 - val_accuracy: 0.9838\n",
      "Epoch 413/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.9836 - val_loss: 0.0450 - val_accuracy: 0.9869\n",
      "Epoch 414/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9867 - val_loss: 0.0468 - val_accuracy: 0.9862\n",
      "Epoch 415/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9849 - val_loss: 0.0476 - val_accuracy: 0.9854\n",
      "Epoch 416/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 0.9861 - val_loss: 0.0461 - val_accuracy: 0.9862\n",
      "Epoch 417/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0463 - accuracy: 0.9879 - val_loss: 0.0461 - val_accuracy: 0.9862\n",
      "Epoch 418/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9856 - val_loss: 0.0558 - val_accuracy: 0.9785\n",
      "Epoch 419/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9849 - val_loss: 0.0459 - val_accuracy: 0.9862\n",
      "Epoch 420/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9874 - val_loss: 0.0449 - val_accuracy: 0.9862\n",
      "Epoch 421/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0459 - accuracy: 0.9861 - val_loss: 0.0441 - val_accuracy: 0.9862\n",
      "Epoch 422/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9874 - val_loss: 0.0450 - val_accuracy: 0.9854\n",
      "Epoch 423/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.9849 - val_loss: 0.0495 - val_accuracy: 0.9862\n",
      "Epoch 424/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9877 - val_loss: 0.0472 - val_accuracy: 0.9862\n",
      "Epoch 425/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 0.9874 - val_loss: 0.0463 - val_accuracy: 0.9869\n",
      "Epoch 426/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0446 - accuracy: 0.9874 - val_loss: 0.0446 - val_accuracy: 0.9862\n",
      "Epoch 427/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9859 - val_loss: 0.0476 - val_accuracy: 0.9862\n",
      "Epoch 428/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0481 - accuracy: 0.9851 - val_loss: 0.0470 - val_accuracy: 0.9862\n",
      "Epoch 429/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0458 - accuracy: 0.9859 - val_loss: 0.0438 - val_accuracy: 0.9862\n",
      "Epoch 430/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0444 - accuracy: 0.9869 - val_loss: 0.0458 - val_accuracy: 0.9869\n",
      "Epoch 431/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0446 - accuracy: 0.9879 - val_loss: 0.0436 - val_accuracy: 0.9862\n",
      "Epoch 432/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "Epoch 433/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.9882 - val_loss: 0.0440 - val_accuracy: 0.9846\n",
      "Epoch 434/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9864 - val_loss: 0.0442 - val_accuracy: 0.9877\n",
      "Epoch 435/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9864 - val_loss: 0.0473 - val_accuracy: 0.9862\n",
      "Epoch 436/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0454 - accuracy: 0.9874 - val_loss: 0.0440 - val_accuracy: 0.9854\n",
      "Epoch 437/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9874 - val_loss: 0.0442 - val_accuracy: 0.9862\n",
      "Epoch 438/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 0.9874 - val_loss: 0.0489 - val_accuracy: 0.9854\n",
      "Epoch 439/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9872 - val_loss: 0.0444 - val_accuracy: 0.9862\n",
      "Epoch 440/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0445 - accuracy: 0.9864 - val_loss: 0.0434 - val_accuracy: 0.9862\n",
      "Epoch 441/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0435 - accuracy: 0.9877 - val_loss: 0.0431 - val_accuracy: 0.9869\n",
      "Epoch 442/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9872 - val_loss: 0.0435 - val_accuracy: 0.9877\n",
      "Epoch 443/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9869 - val_loss: 0.0435 - val_accuracy: 0.9869\n",
      "Epoch 444/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0432 - accuracy: 0.9869 - val_loss: 0.0427 - val_accuracy: 0.9862\n",
      "Epoch 445/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0428 - accuracy: 0.9882 - val_loss: 0.0436 - val_accuracy: 0.9869\n",
      "Epoch 446/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9874 - val_loss: 0.0460 - val_accuracy: 0.9869\n",
      "Epoch 447/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9877 - val_loss: 0.0441 - val_accuracy: 0.9877\n",
      "Epoch 448/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0443 - accuracy: 0.9874 - val_loss: 0.0465 - val_accuracy: 0.9877\n",
      "Epoch 449/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9877 - val_loss: 0.0440 - val_accuracy: 0.9862\n",
      "Epoch 450/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9869 - val_loss: 0.0527 - val_accuracy: 0.9823\n",
      "Epoch 451/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 0.9869 - val_loss: 0.0465 - val_accuracy: 0.9869\n",
      "Epoch 452/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.9877 - val_loss: 0.0481 - val_accuracy: 0.9869\n",
      "Epoch 453/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9869 - val_loss: 0.0459 - val_accuracy: 0.9869\n",
      "Epoch 454/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0461 - accuracy: 0.9856 - val_loss: 0.0426 - val_accuracy: 0.9869\n",
      "Epoch 455/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9867 - val_loss: 0.0431 - val_accuracy: 0.9869\n",
      "Epoch 456/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9885 - val_loss: 0.0423 - val_accuracy: 0.9877\n",
      "Epoch 457/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9879 - val_loss: 0.0438 - val_accuracy: 0.9862\n",
      "Epoch 458/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9867 - val_loss: 0.0431 - val_accuracy: 0.9877\n",
      "Epoch 459/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9877 - val_loss: 0.0444 - val_accuracy: 0.9862\n",
      "Epoch 460/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9887 - val_loss: 0.0460 - val_accuracy: 0.9862\n",
      "Epoch 461/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9869 - val_loss: 0.0430 - val_accuracy: 0.9862\n",
      "Epoch 462/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.9861 - val_loss: 0.0568 - val_accuracy: 0.9800\n",
      "Epoch 463/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0501 - accuracy: 0.9843 - val_loss: 0.0655 - val_accuracy: 0.9762\n",
      "Epoch 464/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0560 - accuracy: 0.9820 - val_loss: 0.0620 - val_accuracy: 0.9754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 0.0497 - val_accuracy: 0.9846\n",
      "Epoch 466/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9846 - val_loss: 0.0450 - val_accuracy: 0.9877\n",
      "Epoch 467/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9867 - val_loss: 0.0426 - val_accuracy: 0.9877\n",
      "Epoch 468/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0426 - accuracy: 0.9877 - val_loss: 0.0410 - val_accuracy: 0.9892\n",
      "Epoch 469/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.9887 - val_loss: 0.0472 - val_accuracy: 0.9877\n",
      "Epoch 470/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9867 - val_loss: 0.0457 - val_accuracy: 0.9877\n",
      "Epoch 471/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9879 - val_loss: 0.0459 - val_accuracy: 0.9869\n",
      "Epoch 472/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9877 - val_loss: 0.0437 - val_accuracy: 0.9869\n",
      "Epoch 473/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.9879 - val_loss: 0.0497 - val_accuracy: 0.9831\n",
      "Epoch 474/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9854 - val_loss: 0.0460 - val_accuracy: 0.9869\n",
      "Epoch 475/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.9869 - val_loss: 0.0432 - val_accuracy: 0.9869\n",
      "Epoch 476/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0411 - accuracy: 0.9879 - val_loss: 0.0416 - val_accuracy: 0.9892\n",
      "Epoch 477/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9882 - val_loss: 0.0421 - val_accuracy: 0.9885\n",
      "Epoch 478/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9887 - val_loss: 0.0429 - val_accuracy: 0.9869\n",
      "Epoch 479/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9879 - val_loss: 0.0425 - val_accuracy: 0.9885\n",
      "Epoch 480/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0411 - accuracy: 0.9885 - val_loss: 0.0419 - val_accuracy: 0.9892\n",
      "Epoch 481/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9882 - val_loss: 0.0439 - val_accuracy: 0.9869\n",
      "Epoch 482/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9879 - val_loss: 0.0433 - val_accuracy: 0.9869\n",
      "Epoch 483/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9885 - val_loss: 0.0427 - val_accuracy: 0.9885\n",
      "Epoch 484/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9879 - val_loss: 0.0421 - val_accuracy: 0.9877\n",
      "Epoch 485/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0443 - accuracy: 0.9869 - val_loss: 0.0436 - val_accuracy: 0.9854\n",
      "Epoch 486/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9874 - val_loss: 0.0509 - val_accuracy: 0.9869\n",
      "Epoch 487/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0428 - accuracy: 0.9874 - val_loss: 0.0430 - val_accuracy: 0.9862\n",
      "Epoch 488/2000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9879 - val_loss: 0.0473 - val_accuracy: 0.9854\n"
     ]
    }
   ],
   "source": [
    "# 학습이 언제 자동 중단 될지를 설정합니다.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "#최적화 모델이 저장될 폴더와 모델의 이름을 정합니다.\n",
    "modelpath=\"./data/model/Ch14-4-bestmodel.hdf5\"\n",
    "\n",
    "# 최적화 모델을 업데이트하고 저장합니다.\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "#모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=1, callbacks=[early_stopping_callback,checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T06:07:03.816791Z",
     "start_time": "2022-12-08T06:07:03.724716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 808us/step - loss: 0.0668 - accuracy: 0.9823\n",
      "Test accuracy: 0.9823076725006104\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
